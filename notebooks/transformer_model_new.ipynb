{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PObN0B-3Sk1w"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import networkx as nx\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from gensim.models import KeyedVectors\n",
    "from node2vec import Node2Vec\n",
    "from shapely.geometry import Point, MultiPolygon\n",
    "from shapely.wkt import loads\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Dataset Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  from google.colab import drive\n",
    "  logger.info(\"Running on Google Colab, reading dataset from drive\")\n",
    "  drive.mount(\"/content/drive\")\n",
    "  DATASET_PATH = \"/content/drive/MyDrive/ECE2500/EdmontonFireRescueServicesData\"\n",
    "except:\n",
    "  logger.info(\"Running locally, reading dataset from local file system\")\n",
    "  DATASET_PATH = \"../dataset/EdmontonFireRescueServicesData\"\n",
    "  if not os.path.exists(DATASET_PATH):\n",
    "    logger.critical(f\"Cannot find dataset directory, place dataset in {DATASET_PATH}\")\n",
    "    exit(1)\n",
    "\n",
    "UNIT_TRIP_PATH = os.path.join(DATASET_PATH, \"EFRS_Unit_Trip_Summary.csv\")\n",
    "WEEKLY_EVENTS_PATH = os.path.join(DATASET_PATH, \"weekly_events.csv\")\n",
    "NEIGHBOURHOOD_PATH = os.path.join(DATASET_PATH, \"City_of_Edmonton_-_Neighbourhoods_20241022.csv\")\n",
    "NEIGHBOURHOOD_FEATURES_PATH = os.path.join(DATASET_PATH, \"neighbourhood_features.csv\")\n",
    "\n",
    "logger.debug(f\"Unit Trip: {UNIT_TRIP_PATH}\")\n",
    "logger.debug(f\"Weekly Events: {WEEKLY_EVENTS_PATH}\")\n",
    "logger.debug(f\"Neighbourhood: {NEIGHBOURHOOD_PATH}\")\n",
    "logger.debug(f\"Neighbourhood Features: {NEIGHBOURHOOD_FEATURES_PATH}\")\n",
    "\n",
    "unit_trip_df = pd.read_csv(UNIT_TRIP_PATH)\n",
    "weekly_events_df_all = pd.read_csv(WEEKLY_EVENTS_PATH)\n",
    "neighbourhood_df = pd.read_csv(NEIGHBOURHOOD_PATH)\n",
    "neighbourhood_feature_df = pd.read_csv(NEIGHBOURHOOD_FEATURES_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_list = ['Emergency Life Threatening - Immediate', 'Emergency Life Threatening', 'Emergency Non-Life Threatening', 'Potential Life Threatening', 'Non-Emergency']\n",
    "weekly_events_df = weekly_events_df_all[weekly_events_df_all['Rc_description'].isin([i for i in event_list])]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fpSHJ3I6onMQ"
   },
   "source": [
    "**Data and Embedding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vkOrdiUYoiTw"
   },
   "outputs": [],
   "source": [
    "def generate_node2vec_embeddings(neighbourhood_info_df, node2vec_dim=32):\n",
    "  \"\"\"\n",
    "  Generates Node2Vec embeddings for neighborhoods based on a sample adjacency graph.\n",
    "  node2vec_dim: Dimension of the embeddings to be generated.\n",
    "  \"\"\"\n",
    "\n",
    "  num_neighborhood_info = len(neighbourhood_info_df)\n",
    "  G = nx.Graph()\n",
    "\n",
    "  # Convert \"Geometry Multipolygon\" column to GeoSeries\n",
    "  neighbourhood_info_df['geometry'] = gpd.GeoSeries.from_wkt(neighbourhood_info_df['Geometry Multipolygon'])\n",
    "  neighbourhood_info_df['nid'] = range(num_neighborhood_info)\n",
    "\n",
    "  # Assuming you have a way to define neighborhood connections based on proximity\n",
    "  # You can use the geometry information for this.\n",
    "  # Here's a placeholder for how you might connect neighborhoods based on proximity:\n",
    "\n",
    "  for i in range(num_neighborhood_info):\n",
    "    for j in range(i + 1, num_neighborhood_info):\n",
    "      # Use the new 'geometry' column for spatial operations\n",
    "      if neighbourhood_info_df['geometry'].iloc[i].intersects(neighbourhood_info_df['geometry'].iloc[j]):\n",
    "        G.add_edge(i, j)\n",
    "\n",
    "  # Alternatively, you could build a graph based on other criteria like sharing a boundary\n",
    "  node2vec = Node2Vec(G, dimensions=node2vec_dim, walk_length=10, num_walks=100, p=1, q=1)\n",
    "  node2vec_model = node2vec.fit()\n",
    "  node2vec_embeddings_np = np.array([node2vec_model.wv[str(i)] for i in range(num_neighborhood_info)])\n",
    "  node2vec_embeddings = torch.from_numpy(node2vec_embeddings_np)\n",
    "  node2vec_emb_layer = nn.Embedding.from_pretrained(node2vec_embeddings, freeze=True)\n",
    "\n",
    "  return node2vec_emb_layer\n",
    "\n",
    "\n",
    "class Time2Vec(nn.Module):\n",
    "  \"\"\"\n",
    "  Time2Vec embedding module for temporal features\n",
    "\n",
    "  This captures both linear and periodic components for time-based features.\n",
    "  \"\"\"\n",
    "  def __init__(self, input_dim, embed_dim, act_function=torch.sin):\n",
    "    super(Time2Vec, self).__init__()\n",
    "    self.embed_dim = embed_dim // input_dim  # Embedding dimension per time feature\n",
    "    self.act_function = act_function       # Activation function for periodicity\n",
    "    self.weight = nn.Parameter(torch.randn(input_dim, self.embed_dim))\n",
    "    self.bias = nn.Parameter(torch.randn(input_dim, self.embed_dim))\n",
    "\n",
    "  def forward(self, x):\n",
    "    # Diagonal embedding for each time feature (day of week, hour, etc.)\n",
    "    x = torch.diag_embed(x)\n",
    "    x_affine = torch.matmul(x, self.weight) + self.bias\n",
    "    x_affine_0, x_affine_remain = torch.split(x_affine, [1, self.embed_dim - 1], dim=-1)\n",
    "    x_affine_remain = self.act_function(x_affine_remain)\n",
    "    return torch.cat([x_affine_0, x_affine_remain], dim=-1).view(x.size(0), x.size(1), -1)\n",
    "\n",
    "\n",
    "class NeighborhoodDataset(Dataset):\n",
    "    def __init__(self, neighborhood_ids, time_features, building_type_ids, building_counts,\n",
    "                 population, event_type_ids, equipment_ids, targets):\n",
    "        self.neighborhood_ids = neighborhood_ids  # Tensor of input neighborhood_ids\n",
    "        self.time_features = time_features  # Tensor of input time_features\n",
    "        self.building_type_ids = building_type_ids  # Tensor of input building_type_ids\n",
    "        self.building_counts = building_counts  # Tensor of input building_counts\n",
    "        self.population = population  # Tensor of input population\n",
    "        self.event_type_ids = event_type_ids  # Tensor of input event_type_ids\n",
    "        self.equipment_ids = equipment_ids  # Tensor of input equipment_ids\n",
    "        self.targets = targets    # Tensor of target values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.neighborhood_ids)  # Number of neighborhoods\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.neighborhood_ids[idx], self.time_features[idx], self.building_type_ids[idx], self.building_counts[idx],\n",
    "                self.population[idx], self.event_type_ids[idx], self.equipment_ids[idx], self.targets[idx])\n",
    "\n",
    "\n",
    "class CombinedEmbedding(nn.Module):\n",
    "  \"\"\"\n",
    "  Combined Embedding Module\n",
    "\n",
    "  Combines embeddings from Node2Vec, Time2Vec, building type/counts, population, event type, and equipment.\n",
    "  Projects the combined embedding to a target dimension (e.g., 64) for compatibility with transformer layers.\n",
    "  \"\"\"\n",
    "  def __init__(self, node2vec_emb_layer, time2vec_embed_dim, time_feature_dim,\n",
    "          num_building_types, building_type_embed_dim, population_embed_dim,\n",
    "          num_event_types, event_type_embed_dim, num_equipment_types, equipment_embed_dim,\n",
    "          target_embed_dim=64):  # Add target_embed_dim for projection\n",
    "    super(CombinedEmbedding, self).__init__()\n",
    "\n",
    "    # Embedding initialization code\n",
    "    self.node2vec_emb_layer = node2vec_emb_layer  # Precomputed Node2Vec embeddings\n",
    "    self.time2vec = Time2Vec(input_dim=time_feature_dim, embed_dim=time2vec_embed_dim)\n",
    "    self.building_type_embedding = nn.Embedding(num_building_types, building_type_embed_dim)\n",
    "    self.population_embedding = nn.Linear(1, population_embed_dim)\n",
    "    # self.income_embedding = nn.Linear(1, income_embed_dim)\n",
    "    self.event_type_embedding = nn.Embedding(num_event_types, event_type_embed_dim)\n",
    "    self.equipment_embedding = nn.Embedding(num_equipment_types, equipment_embed_dim)\n",
    "\n",
    "    # Compute the combined embedding dimension before projection\n",
    "    # num_neighbourhood * 2 (month + year) * x\n",
    "    self.projection_dim = (node2vec_emb_layer.embedding_dim + time2vec_embed_dim +\n",
    "                    building_type_embed_dim + population_embed_dim +\n",
    "                    event_type_embed_dim + equipment_embed_dim)\n",
    "\n",
    "    # Projection layer to reduce to target_embed_dim\n",
    "    self.projection_layer = nn.Linear(self.projection_dim, target_embed_dim)\n",
    "    \n",
    "  def forward(self, neighborhood_ids, time_features, building_type_ids, building_counts,\n",
    "            population, event_type_ids, equipment_ids):\n",
    "    # Generate embeddings\n",
    "    spatial_embeddings = self.node2vec_emb_layer(neighborhood_ids).unsqueeze(1).repeat(1, time_features.size(1), 1)\n",
    "    logger.debug(f\"Spatial Embedding Shape: {spatial_embeddings.shape}\")\n",
    "\n",
    "    temporal_embeddings = self.time2vec(time_features)\n",
    "    logger.debug(f\"Temporal Embedding Shape: {temporal_embeddings.shape}\")\n",
    "\n",
    "    # Building embeddings\n",
    "    building_type_embeds = self.building_type_embedding(building_type_ids)  # Shape: [batch_size, num_building_types, building_type_embed_dim]\n",
    "    logger.debug(f\"Building Type Embeds Shape: {building_type_embeds.shape}\")\n",
    "\n",
    "    # Adjust building_counts to match building_type_embed_dim\n",
    "    building_counts = building_counts.unsqueeze(-1)  # Shape: [batch_size, 1, num_building_types, 1]\n",
    "    building_counts = building_counts.repeat(1, 1, 1, self.building_type_embedding.embedding_dim)  # Match embed_dim\n",
    "    logger.debug(f\"Building Counts Shape after adjustment: {building_counts.shape}\")\n",
    "\n",
    "    # Multiply and aggregate\n",
    "    building_embeddings = (building_type_embeds.unsqueeze(1) * building_counts).sum(dim=2)  # Shape: [batch_size, 1, building_type_embed_dim]\n",
    "    building_embeddings = building_embeddings.repeat(1, time_features.size(1), 1)  # Match temporal dimension\n",
    "    logger.debug(f\"Building Embedding Shape: {building_embeddings.shape}\")\n",
    "\n",
    "    population_embeddings = self.population_embedding(population.unsqueeze(-1)).unsqueeze(1).repeat(1, time_features.size(1), 1)\n",
    "    logger.debug(f\"Population Embedding Shape: {population_embeddings.shape}\")\n",
    "\n",
    "    event_type_embeddings = self.event_type_embedding(event_type_ids)\n",
    "    logger.debug(f\"Event Type Embedding Shape: {event_type_embeddings.shape}\")\n",
    "\n",
    "    equipment_embeddings = self.equipment_embedding(equipment_ids)\n",
    "    logger.debug(f\"Equipment Embedding Shape: {equipment_embeddings.shape}\")\n",
    "\n",
    "    # Concatenate all embeddings\n",
    "    combined_embedding = torch.cat([spatial_embeddings, temporal_embeddings, building_embeddings,\n",
    "                                     population_embeddings, event_type_embeddings, equipment_embeddings], dim=-1)\n",
    "    logger.debug(f\"Combined Embedding Shape before Projection: {combined_embedding.shape}\")\n",
    "\n",
    "    # Project to target dimension\n",
    "    combined_embedding = self.projection_layer(combined_embedding)\n",
    "    return combined_embedding\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "  \"\"\"\n",
    "  Positional Encoding Module\n",
    "  \"\"\"\n",
    "  def __init__(self, embed_dim, max_len=7):  # 7 days in a week\n",
    "    super(PositionalEncoding, self).__init__()\n",
    "    position = torch.arange(0, max_len).unsqueeze(1)\n",
    "    div_term = torch.exp(torch.arange(0, embed_dim, 2) * - (math.log(10000.0) / embed_dim))\n",
    "    pe = torch.zeros(max_len, embed_dim)\n",
    "    pe[:, 0::2] = torch.sin(position * div_term)\n",
    "    pe[:, 1::2] = torch.cos(position * div_term)\n",
    "    self.pe = pe.unsqueeze(0)  # Shape: (1, max_len, embed_dim)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = x + self.pe[:, :x.size(1), :].to(x.device)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5mZCuFUYtYpm"
   },
   "source": [
    "**Transformer Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p3CHjlqytU2a"
   },
   "outputs": [],
   "source": [
    "# Transformer-based Emergency Event Predictor\n",
    "class EmergencyEventPredictor(nn.Module):\n",
    "  def __init__(self, embedding_module, embed_dim, num_heads, num_layers, max_len=7):\n",
    "    super(EmergencyEventPredictor, self).__init__()\n",
    "\n",
    "    # Embedding module (CombinedEmbedding) and positional encoding\n",
    "    self.embedding_module = embedding_module\n",
    "    self.positional_encoding = PositionalEncoding(embed_dim, max_len)\n",
    "\n",
    "    # Transformer Encoder\n",
    "    encoder_layer = nn.TransformerEncoderLayer(\n",
    "        d_model=embed_dim, nhead=num_heads, dim_feedforward=512, dropout=0.1\n",
    "    )\n",
    "    self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "    # Prediction head\n",
    "    self.fc_out = nn.Linear(embed_dim, 1)  # Output: predicting the number of events\n",
    "\n",
    "  def forward(self, neighborhood_ids, time_features, building_type_ids, building_counts,\n",
    "              population, event_type_ids, equipment_ids):\n",
    "\n",
    "    # Generate combined embeddings from the embedding module\n",
    "    x = self.embedding_module(neighborhood_ids, time_features, building_type_ids, building_counts,\n",
    "                              population, event_type_ids, equipment_ids)\n",
    "\n",
    "    # Apply positional encoding\n",
    "    x = self.positional_encoding(x)\n",
    "\n",
    "    # Pass through transformer encoder\n",
    "    x = self.transformer_encoder(x)\n",
    "\n",
    "    # Prediction layer (we apply it to each element in the sequence)\n",
    "    # Albert: predictions = self.fc_out(x).squeeze(-1)  # Shape: [batch_size]\n",
    "    predictions = self.fc_out(x.squeeze(1)).squeeze(-1)  # Shape: [batch_size]\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Extraction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_type_list = [\n",
    "    'Apartment_Condo_1_to_4_stories', 'Apartment_Condo_5_or_more_stories',\n",
    "    'Duplex_Fourplex', 'Hotel_Motel',\n",
    "    'Institution_Collective_Residence', 'Manufactured_Mobile_Home',\n",
    "    'RV_Tent_Other', 'Row_House',\n",
    "    'Single_Detached_House'\n",
    "    ]\n",
    "income_list = ['Low_Income', 'Low_medium_Income', 'Medium_Income', 'High_Income']\n",
    "event_type_list = weekly_events_df['Rc_description'].unique()\n",
    "unit_type_list = unit_trip_df['unityp'].unique()\n",
    "\n",
    "num_neighborhoods = len(neighbourhood_feature_df)\n",
    "num_income = len(income_list)\n",
    "num_building_types = len(build_type_list)\n",
    "num_event_types = len(event_type_list)\n",
    "num_equipment_types = len(unit_type_list)\n",
    "\n",
    "neighbourhood_mappings = weekly_events_df[\"Neighbourhood Number\"].unique()\n",
    "building_counts_np = neighbourhood_feature_df[build_type_list].fillna(0).astype(int).to_numpy()\n",
    "population_np = neighbourhood_feature_df['Population'].fillna(0).astype(int).to_numpy()\n",
    "income_np = neighbourhood_feature_df[income_list].fillna(0).astype(int).to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transformer Model Initalization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AEKcsqMG3l9T",
    "outputId": "71924b64-6378-4397-e650-8fc33a4f8b57"
   },
   "outputs": [],
   "source": [
    "# Embedding Parameter and Module\n",
    "\n",
    "node2vec_dim = 32\n",
    "time2vec_embed_dim = 64\n",
    "time_feature_dim = 2  # week, year\n",
    "building_type_embed_dim = 16\n",
    "population_embed_dim = 8\n",
    "event_type_embed_dim = 16\n",
    "equipment_embed_dim = 16\n",
    "target_embed_dim = 64\n",
    "\n",
    "node2vec_emb_layer = generate_node2vec_embeddings(\n",
    "    neighbourhood_info_df=neighbourhood_df,\n",
    "    node2vec_dim=node2vec_dim\n",
    ")\n",
    "\n",
    "embedding_module = CombinedEmbedding(\n",
    "    node2vec_emb_layer=node2vec_emb_layer,\n",
    "    time2vec_embed_dim=time2vec_embed_dim,\n",
    "    time_feature_dim=time_feature_dim,\n",
    "    num_building_types=num_building_types,\n",
    "    building_type_embed_dim=building_type_embed_dim,\n",
    "    population_embed_dim=population_embed_dim,\n",
    "    num_event_types=num_event_types,\n",
    "    event_type_embed_dim=event_type_embed_dim,\n",
    "    num_equipment_types=num_equipment_types,\n",
    "    equipment_embed_dim=equipment_embed_dim,\n",
    "    target_embed_dim=target_embed_dim\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define batch and mini-batch\n",
    "\n",
    "mini_batch_size = 29\n",
    "batch_size = 13\n",
    "\n",
    "spatial_dimension = num_neighborhoods\n",
    "\n",
    "# verify spatial_dimension = batch_size * mini_batch_size\n",
    "assert spatial_dimension == batch_size * mini_batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neighborhood Features\n",
    "neighborhood_ids = torch.arange(num_neighborhoods)\n",
    "logger.info(f\"neighborhood_ids shape {neighborhood_ids.shape}\")\n",
    "\n",
    "# Time Features\n",
    "time_features = torch.zeros(spatial_dimension, 1, time_feature_dim) # [# years, # weeks]\n",
    "for nid in range(num_neighborhoods):\n",
    "    # Filter rows for the current neighborhood\n",
    "    neighborhood_data = weekly_events_df[weekly_events_df[\"Neighbourhood Number\"] == neighbourhood_mappings[nid]]\n",
    "\n",
    "    if not neighborhood_data.empty:\n",
    "        # Use \"year\" and \"week_of_year\" as features\n",
    "        year_mean = neighborhood_data[\"year\"].mean()\n",
    "        week_mean = neighborhood_data[\"week_of_year\"].mean()\n",
    "\n",
    "        # Combine them into time features (e.g., [mean year, mean week])\n",
    "        time_features[nid, 0, :] = torch.tensor([year_mean, week_mean])\n",
    "    else:\n",
    "        # Default to zero if no data for the neighborhood\n",
    "        time_features[nid, 0, :] = torch.zeros(time_feature_dim)\n",
    "\n",
    "logger.info(f\"time_features shape: {time_features.shape}\")\n",
    "\n",
    "# Building Features\n",
    "building_type_ids = torch.arange(num_building_types).repeat(spatial_dimension, 1)\n",
    "logger.info(f\"building_type_ids shape {building_type_ids.shape}\")\n",
    "\n",
    "# Building Counts\n",
    "building_counts_np = neighbourhood_feature_df[build_type_list].fillna(0).to_numpy(dtype=np.int32)\n",
    "building_counts = torch.from_numpy(building_counts_np).unsqueeze(1)  # Temporal dimension = 1\n",
    "logger.info(f\"building_counts shape {building_counts.shape}\")\n",
    "\n",
    "# Demographic Features\n",
    "population = torch.from_numpy(population_np).float()\n",
    "logger.info(f\"population shape {population.shape}\")\n",
    "\n",
    "income = torch.from_numpy(income_np).float()\n",
    "logger.info(f\"income shape {income.shape}\")\n",
    "\n",
    "# Event Features\n",
    "event_type_ids = torch.randint(0, num_event_types, (spatial_dimension, 1))  # Temporal dimension = 1\n",
    "logger.info(f\"event_type_ids shape {event_type_ids.shape}\")\n",
    "\n",
    "equipment_ids = torch.randint(0, num_equipment_types, (spatial_dimension, 1))  # Temporal dimension = 1\n",
    "logger.info(f\"equipment_ids shape {equipment_ids.shape}\")\n",
    "\n",
    "# Target Values\n",
    "agg_data = weekly_events_df.groupby(['year', 'week_of_year', 'Neighbourhood Number']).agg({\n",
    "    'Rc_description': ' '.join,  # Concatenate descriptions (or other aggregation if needed)\n",
    "    'event_count': 'sum'         # Sum event counts\n",
    "}).reset_index()\n",
    "\n",
    "unique_week_year_combinations = agg_data[['year', 'week_of_year']].drop_duplicates()\n",
    "targets = torch.zeros((num_neighborhoods,), dtype=torch.float32)\n",
    "\n",
    "for i, neighbourhood in enumerate(neighbourhood_feature_df['Neighbourhood_Number']):\n",
    "    neighbourhood_data = agg_data[agg_data['Neighbourhood Number'] == neighbourhood]\n",
    "    # Sum of event counts for each (year, week_of_year) combination\n",
    "    for k, (year, week) in enumerate(unique_week_year_combinations.itertuples(index=False)):\n",
    "        event_count = neighbourhood_data[(neighbourhood_data['year'] == year) &\n",
    "                                         (neighbourhood_data['week_of_year'] == week)]['event_count'].sum()\n",
    "        targets[i] = event_count  # Aggregated for the entire week\n",
    "logger.info(f\"targets shape {targets.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dutQ0WcSgki5"
   },
   "source": [
    "**Transformer Model Training Loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the DataLoader and EmergencyEventPredictor\n",
    "dataset = NeighborhoodDataset(neighborhood_ids, time_features, building_type_ids, building_counts,\n",
    "                              population, event_type_ids, equipment_ids, targets)\n",
    "dataloader = DataLoader(dataset, batch_size=mini_batch_size, shuffle=True)\n",
    "\n",
    "model = EmergencyEventPredictor(\n",
    "    embedding_module=embedding_module,\n",
    "    embed_dim=64,\n",
    "    num_heads=4,\n",
    "    num_layers=2\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.PoissonNLLLoss()\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 500\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for i, (_neighborhood_ids, _time_features, _building_type_ids, _building_counts,\n",
    "            _population, _event_type_ids, _equipment_ids, _targets) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        _predictions = model(_neighborhood_ids, _time_features, _building_type_ids,\n",
    "                             _building_counts, _population, _event_type_ids, _equipment_ids)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(_predictions, _targets)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        mini_batch_loss = loss.item()\n",
    "        epoch_loss += mini_batch_loss\n",
    "        logger.debug(f\"Epoch [{epoch+1}/{num_epochs}], Mini-batch [{i + 1}/{len(dataloader)}], Loss: {mini_batch_loss:.4f}\")\n",
    "\n",
    "    logger.info(f\"Epoch [{epoch+1}/{num_epochs}] completed, Average Loss: {(epoch_loss / len(dataloader)):.4f}\")\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), \"transformer_model_weekly.pth\")\n",
    "logger.info(\"Model saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9TvUntsoge8Y"
   },
   "source": [
    "**Transformer Model Prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cxb72D9VpkkX",
    "outputId": "fe762711-2f22-4eb6-ef1d-e00e3503b670"
   },
   "outputs": [],
   "source": [
    "# Define model parameters\n",
    "embed_dim = target_embed_dim  # Same as output dimension of CombinedEmbedding\n",
    "num_heads = 4\n",
    "num_layers = 2\n",
    "max_len = 7  # Sequence length (e.g., 7 days for a weekly prediction)\n",
    "\n",
    "# Instantiate the model\n",
    "model = EmergencyEventPredictor(\n",
    "    embedding_module=embedding_module,  # Replace with actual CombinedEmbedding instance\n",
    "    embed_dim=embed_dim,\n",
    "    num_heads=num_heads,\n",
    "    num_layers=num_layers,\n",
    "    max_len=max_len\n",
    ")\n",
    "\n",
    "# Forward pass to get predictions\n",
    "predictions = model(\n",
    "    neighborhood_ids=neighborhood_ids,\n",
    "    time_features=time_features,\n",
    "    building_type_ids=building_type_ids,\n",
    "    building_counts=building_counts,\n",
    "    population=population,\n",
    "    event_type_ids=event_type_ids,\n",
    "    equipment_ids=equipment_ids\n",
    ")\n",
    "\n",
    "logger.info(f\"Predictions Shape: {predictions.shape}\")\n",
    "logger.info(f\"Predictions: {predictions}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Diagram**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install torchviz\n",
    "# from torchviz import make_dot\n",
    "# make_dot(predictions, params=dict(model.named_parameters())).render(\"model_architecture\", format=\"png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q9Kjcq-dgur_"
   },
   "source": [
    "**Output Visulization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "2D1qgftI2cL4",
    "outputId": "37e8dbeb-7e1a-4eca-dd94-c317f2c9d94b"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Detach predictions and convert to NumPy for visualization\n",
    "predictions_np = predictions.detach().numpy()\n",
    "predictions_np = predictions_np.reshape(-1, 1) # shape (377, 1)\n",
    "\n",
    "# Define the plot\n",
    "plt.figure(figsize=(12, 100))\n",
    "sns.heatmap(predictions_np, annot=True, cmap=\"coolwarm\", cbar=True, fmt=\".2f\",\n",
    "            xticklabels=[f\"Week {i+1}\" for i in range(predictions_np.shape[1])],\n",
    "            yticklabels=[f\"Neighborhood {i+1}\" for i in range(predictions_np.shape[0])])\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title(\"Predicted Number of Events per Day for Each Neighborhood\")\n",
    "plt.xlabel(\"Day of the Week\")\n",
    "plt.ylabel(\"Neighborhood\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting neighborhoods into train and validation sets\n",
    "train_indices, val_indices = train_test_split(\n",
    "    np.arange(num_neighborhoods), test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Prepare validation tensors\n",
    "train_neighborhood_ids = neighborhood_ids[train_indices]\n",
    "train_time_features = time_features[train_indices]\n",
    "train_building_type_ids = building_type_ids[train_indices]\n",
    "train_building_counts = building_counts[train_indices]\n",
    "train_population = population[train_indices]\n",
    "train_event_type_ids = event_type_ids[train_indices]\n",
    "train_equipment_ids = equipment_ids[train_indices]\n",
    "train_targets = targets[train_indices]\n",
    "\n",
    "# Prepare validation tensors\n",
    "val_neighborhood_ids = neighborhood_ids[val_indices]\n",
    "val_time_features = time_features[val_indices]\n",
    "val_building_type_ids = building_type_ids[val_indices]\n",
    "val_building_counts = building_counts[val_indices]\n",
    "val_population = population[val_indices]\n",
    "val_event_type_ids = event_type_ids[val_indices]\n",
    "val_equipment_ids = equipment_ids[val_indices]\n",
    "val_targets = targets[val_indices]\n",
    "\n",
    "# Create Validation Dataset and DataLoader\n",
    "val_dataset = NeighborhoodDataset(\n",
    "    neighborhood_ids=val_neighborhood_ids,\n",
    "    time_features=val_time_features,\n",
    "    building_type_ids=val_building_type_ids,\n",
    "    building_counts=val_building_counts,\n",
    "    population=val_population,\n",
    "    event_type_ids=val_event_type_ids,\n",
    "    equipment_ids=val_equipment_ids,\n",
    "    targets=val_targets\n",
    ")\n",
    "train_dataset = NeighborhoodDataset(\n",
    "    neighborhood_ids=train_neighborhood_ids,\n",
    "    time_features=train_time_features,\n",
    "    building_type_ids=train_building_type_ids,\n",
    "    building_counts=train_building_counts,\n",
    "    population=train_population,\n",
    "    event_type_ids=train_event_type_ids,\n",
    "    equipment_ids=train_equipment_ids,\n",
    "    targets=train_targets\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# Validation Loop\n",
    "def validate_model(model, val_dataloader):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        i = 0\n",
    "        for (_neighborhood_ids, _time_features, _building_type_ids, _building_counts,\n",
    "             _population, _event_type_ids, _equipment_ids, _targets) in val_dataloader:\n",
    "            \n",
    "            # Forward pass\n",
    "            _predictions = model(_neighborhood_ids, _time_features, _building_type_ids,\n",
    "                                 _building_counts, _population, _event_type_ids, _equipment_ids)\n",
    "\n",
    "            # Collect predictions and true values\n",
    "            all_predictions.append(_predictions.cpu().numpy())\n",
    "            all_targets.append(_targets.cpu().numpy())\n",
    "    \n",
    "    # Combine all batches\n",
    "    all_predictions = np.concatenate(all_predictions, axis=0)\n",
    "    all_targets = np.concatenate(all_targets, axis=0)\n",
    "\n",
    "    # Compute metrics\n",
    "    print(f\"all_targets {all_targets.shape}, all_predictions {all_predictions.shape}\")\n",
    "    mae = mean_absolute_error(all_targets, all_predictions)\n",
    "    mse = mean_squared_error(all_targets, all_predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(all_targets, all_predictions)\n",
    "\n",
    "    print(f\"Validation Results:\")\n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "    print(f\"MSE: {mse:.4f}\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"R² Score: {r2:.4f}\")\n",
    "\n",
    "    return all_predictions, all_targets\n",
    "\n",
    "# Scatter Plot: Predicted vs. True Values\n",
    "def plot_predictions_vs_true(all_predictions, all_targets):\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.scatter(all_targets, all_predictions, alpha=0.5, edgecolor='k')\n",
    "    plt.plot([all_targets.min(), all_targets.max()], [all_targets.min(), all_targets.max()], 'r--')\n",
    "    plt.title(\"Predicted vs True Event Counts\")\n",
    "    plt.xlabel(\"True Event Counts\")\n",
    "    plt.ylabel(\"Predicted Event Counts\")\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "# Heatmap: Neighborhood Predictions Over Time\n",
    "def plot_heatmap(all_predictions, neighborhood_ids):\n",
    "    if len(all_predictions.shape) == 1:\n",
    "        all_predictions = all_predictions.reshape(-1, 1) # shape (377, 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 20))\n",
    "    sns.heatmap(all_predictions, annot=True, cmap=\"coolwarm\", cbar=True, fmt=\".2f\",\n",
    "                xticklabels=[f\"Week {i+1}\" for i in range(all_predictions.shape[1])],\n",
    "                yticklabels=[f\"Neighborhood {i}\" for i in neighborhood_ids])\n",
    "    plt.title(\"Predicted Event Counts per Neighborhood per Day\")\n",
    "    plt.xlabel(\"Days\")\n",
    "    plt.ylabel(\"Neighborhood\")\n",
    "    plt.show()\n",
    "\n",
    "# Perform validation\n",
    "all_predictions, all_targets = validate_model(model, val_dataloader)\n",
    "\n",
    "# Visualize results\n",
    "plot_predictions_vs_true(all_predictions, all_targets)\n",
    "plot_heatmap(all_predictions, val_neighborhood_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(len(all_predictions))  # Positions for the first list\n",
    "width = 0.4  # Width of the bars\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(30, 5))\n",
    "plt.bar(x - width / 2, all_predictions, width=width, label='all_predictions', color='skyblue')\n",
    "plt.bar(x + width / 2, all_targets, width=width, label='all_targets', color='orange')\n",
    "\n",
    "# Add labels, title, and legend\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Values')\n",
    "plt.title('Side-by-Side Bar Plot of Two Lists')\n",
    "plt.xticks(x, [f'Item {i}' for i in range(len(all_predictions))])  # Label x-axis ticks\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to calculate metrics\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    y_true = y_true.cpu().numpy() if isinstance(y_true, torch.Tensor) else y_true\n",
    "    y_pred = y_pred.cpu().detach().numpy() if isinstance(y_pred, torch.Tensor) else y_pred\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return mae, mse, rmse, r2\n",
    "\n",
    "# Lists to store metrics\n",
    "train_losses, val_losses = [], []\n",
    "train_maes, val_maes = [], []\n",
    "train_rmses, val_rmses = [], []\n",
    "\n",
    "# Training loop with validation\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_preds, train_targets = [], []\n",
    "\n",
    "    for i, (_neighborhood_ids, _time_features, _building_type_ids, _building_counts,\n",
    "            _population, _event_type_ids, _equipment_ids, _targets) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        _predictions = model(_neighborhood_ids, _time_features, _building_type_ids,\n",
    "                             _building_counts, _population, _event_type_ids, _equipment_ids)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(_predictions, _targets)\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Collect predictions and targets for metrics\n",
    "        train_preds.append(_predictions)\n",
    "        train_targets.append(_targets)\n",
    "\n",
    "    # Concatenate all training predictions and targets\n",
    "    train_preds = torch.cat(train_preds)\n",
    "    train_targets = torch.cat(train_targets)\n",
    "    train_mae, train_mse, train_rmse, train_r2 = calculate_metrics(train_targets, train_preds)\n",
    "    train_losses.append(train_loss / len(dataloader))\n",
    "    train_maes.append(train_mae)\n",
    "    train_rmses.append(train_rmse)\n",
    "\n",
    "    logger.info(f\"Epoch [{epoch+1}/{num_epochs}] Training Loss: {train_loss/len(dataloader):.4f}\")\n",
    "    logger.info(f\"Training Metrics - MAE: {train_mae:.4f}, MSE: {train_mse:.4f}, RMSE: {train_rmse:.4f}, R²: {train_r2:.4f}\")\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_preds, val_targets = [], []\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (_neighborhood_ids, _time_features, _building_type_ids, _building_counts,\n",
    "                _population, _event_type_ids, _equipment_ids, _targets) in enumerate(val_dataloader):\n",
    "            \n",
    "            # Forward pass\n",
    "            _predictions = model(_neighborhood_ids, _time_features, _building_type_ids,\n",
    "                                 _building_counts, _population, _event_type_ids, _equipment_ids)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = criterion(_predictions, _targets)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # Collect predictions and targets for metrics\n",
    "            val_preds.append(_predictions)\n",
    "            val_targets.append(_targets)\n",
    "\n",
    "    # Concatenate all validation predictions and targets\n",
    "    val_preds = torch.cat(val_preds)\n",
    "    val_targets = torch.cat(val_targets)\n",
    "    val_mae, val_mse, val_rmse, val_r2 = calculate_metrics(val_targets, val_preds)\n",
    "    val_losses.append(val_loss / len(val_dataloader))\n",
    "    val_maes.append(val_mae)\n",
    "    val_rmses.append(val_rmse)\n",
    "\n",
    "    logger.info(f\"Epoch [{epoch+1}/{num_epochs}] Validation Loss: {val_loss/len(val_dataloader):.4f}\")\n",
    "    logger.info(f\"Validation Metrics - MAE: {val_mae:.4f}, MSE: {val_mse:.4f}, RMSE: {val_rmse:.4f}, R²: {val_r2:.4f}\")\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), \"transformer_model_weekly.pth\")\n",
    "logger.info(\"Model saved successfully.\")\n",
    "\n",
    "# Visualization\n",
    "epochs = range(1, num_epochs + 1)\n",
    "\n",
    "# Plot Losses\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, train_losses, label=\"Training Loss\")\n",
    "plt.plot(epochs, val_losses, label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot MAE\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, train_maes, label=\"Training MAE\")\n",
    "plt.plot(epochs, val_maes, label=\"Validation MAE\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Mean Absolute Error\")\n",
    "plt.title(\"Training and Validation MAE\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot RMSE\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, train_rmses, label=\"Training RMSE\")\n",
    "plt.plot(epochs, val_rmses, label=\"Validation RMSE\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Root Mean Squared Error\")\n",
    "plt.title(\"Training and Validation RMSE\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the calculate_accuracy function\n",
    "def calculate_accuracy(y_true, y_pred, tolerance=0.5):\n",
    "    \"\"\"\n",
    "    Calculate accuracy for regression by considering predictions\n",
    "    within a certain tolerance as correct.\n",
    "\n",
    "    Args:\n",
    "        y_true: True target values (Tensor or NumPy array).\n",
    "        y_pred: Predicted values from the model (Tensor or NumPy array).\n",
    "        tolerance: Acceptable error margin.\n",
    "\n",
    "    Returns:\n",
    "        Accuracy as a percentage.\n",
    "    \"\"\"\n",
    "    y_true = y_true.cpu().numpy() if isinstance(y_true, torch.Tensor) else y_true\n",
    "    y_pred = y_pred.cpu().detach().numpy() if isinstance(y_pred, torch.Tensor) else y_pred\n",
    "\n",
    "    correct = np.abs(y_pred - y_true) <= tolerance\n",
    "    accuracy = np.mean(correct) * 100  # Convert to percentage\n",
    "    return accuracy\n",
    "\n",
    "# Training and validation loop\n",
    "num_epochs = 100\n",
    "train_losses, val_losses = [], []\n",
    "train_accuracies, val_accuracies = [], []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_preds, train_targets = [], []\n",
    "\n",
    "    for i, (_neighborhood_ids, _time_features, _building_type_ids, _building_counts,\n",
    "            _population, _event_type_ids, _equipment_ids, _targets) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        _predictions = model(_neighborhood_ids, _time_features, _building_type_ids,\n",
    "                             _building_counts, _population, _event_type_ids, _equipment_ids)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(_predictions, _targets)\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Collect predictions and targets for metrics\n",
    "        train_preds.append(_predictions)\n",
    "        train_targets.append(_targets)\n",
    "\n",
    "    # Concatenate all training predictions and targets\n",
    "    train_preds = torch.cat(train_preds)\n",
    "    train_targets = torch.cat(train_targets)\n",
    "    train_accuracy = calculate_accuracy(train_targets, train_preds)\n",
    "    train_losses.append(train_loss / len(dataloader))\n",
    "    train_accuracies.append(train_accuracy)\n",
    "\n",
    "    logger.info(f\"Epoch [{epoch+1}/{num_epochs}] Training Loss: {train_loss:.4f}, Training Accuracy: {train_accuracy:.2f}%\")\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_preds, val_targets = [], []\n",
    "    val_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (_neighborhood_ids, _time_features, _building_type_ids, _building_counts,\n",
    "                _population, _event_type_ids, _equipment_ids, _targets) in enumerate(val_dataloader):\n",
    "            \n",
    "            # Forward pass\n",
    "            _predictions = model(_neighborhood_ids, _time_features, _building_type_ids,\n",
    "                                 _building_counts, _population, _event_type_ids, _equipment_ids)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = criterion(_predictions, _targets)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # Collect predictions and targets for metrics\n",
    "            val_preds.append(_predictions)\n",
    "            val_targets.append(_targets)\n",
    "\n",
    "    # Concatenate all validation predictions and targets\n",
    "    val_preds = torch.cat(val_preds)\n",
    "    val_targets = torch.cat(val_targets)\n",
    "    val_accuracy = calculate_accuracy(val_targets, val_preds)\n",
    "    val_losses.append(val_loss / len(val_dataloader))\n",
    "    val_accuracies.append(val_accuracy)\n",
    "\n",
    "    logger.info(f\"Epoch [{epoch+1}/{num_epochs}] Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), \"transformer_model_with_accuracy.pth\")\n",
    "logger.info(\"Model saved successfully.\")\n",
    "\n",
    "# Plot Loss\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(range(1, num_epochs + 1), train_losses, label=\"Training Loss\")\n",
    "plt.plot(range(1, num_epochs + 1), val_losses, label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Plot Accuracy\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(range(1, num_epochs + 1), train_accuracies, label=\"Training Accuracy\")\n",
    "plt.plot(range(1, num_epochs + 1), val_accuracies, label=\"Validation Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.title(\"Training and Validation Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Variance-Bias Trade-off Analysis\n",
    "bias = [train_loss - train_acc for train_loss, train_acc in zip(train_losses, train_accuracies)]\n",
    "variance = [val_loss - val_acc for val_loss, val_acc in zip(val_losses, val_accuracies)]\n",
    "\n",
    "# Plot Variance-Bias Trade-off\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(range(1, num_epochs + 1), bias, label=\"Bias\")\n",
    "plt.plot(range(1, num_epochs + 1), variance, label=\"Variance\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.title(\"Variance-Bias Trade-off\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "\n",
    "\n",
    "# Training and validation loop with plotting\n",
    "def train_and_evaluate(model, train_loader, val_loader, optimizer, criterion, num_epochs):\n",
    "    train_losses, val_losses = [], []\n",
    "    train_accuracies, val_accuracies = [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training Phase\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_preds, train_targets = [], []\n",
    "\n",
    "        for batch in train_loader:\n",
    "            neighborhood_ids, time_features, building_type_ids, building_counts, population, event_type_ids, equipment_ids, targets = batch\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            predictions = model(neighborhood_ids, time_features, building_type_ids,\n",
    "                                building_counts, population, event_type_ids, equipment_ids)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = criterion(predictions, targets)\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Store predictions and targets for accuracy calculation\n",
    "            train_preds.append(predictions)\n",
    "            train_targets.append(targets)\n",
    "\n",
    "        # Calculate average training loss and accuracy\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "\n",
    "        train_preds = torch.cat(train_preds)\n",
    "        train_targets = torch.cat(train_targets)\n",
    "        train_accuracy = calculate_accuracy(train_targets, train_preds)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "\n",
    "        # Validation Phase\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_preds, val_targets = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                neighborhood_ids, time_features, building_type_ids, building_counts, population, event_type_ids, equipment_ids, targets = batch\n",
    "\n",
    "                # Forward pass\n",
    "                predictions = model(neighborhood_ids, time_features, building_type_ids,\n",
    "                                    building_counts, population, event_type_ids, equipment_ids)\n",
    "\n",
    "                # Compute loss\n",
    "                loss = criterion(predictions, targets)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                # Store predictions and targets for accuracy calculation\n",
    "                val_preds.append(predictions)\n",
    "                val_targets.append(targets)\n",
    "\n",
    "        # Calculate average validation loss and accuracy\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_losses.append(avg_val_loss)\n",
    "\n",
    "        val_preds = torch.cat(val_preds)\n",
    "        val_targets = torch.cat(val_targets)\n",
    "        val_accuracy = calculate_accuracy(val_targets, val_preds)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "\n",
    "        # Logging\n",
    "        logger.info(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "        logger.info(f\"Training Loss: {avg_train_loss:.4f}, Training Accuracy: {train_accuracy:.2f}%\")\n",
    "        logger.info(f\"Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\\n\")\n",
    "\n",
    "    # Plotting Training and Validation Loss\n",
    "    epochs = range(1, num_epochs + 1)\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.plot(epochs, train_losses, label='Training Loss')\n",
    "    plt.plot(epochs, val_losses, label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # Plotting Training and Validation Accuracy\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.plot(epochs, train_accuracies, label='Training Accuracy')\n",
    "    plt.plot(epochs, val_accuracies, label='Validation Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # Variance-Bias Trade-off Analysis\n",
    "    # In regression, bias and variance can be analyzed by comparing training and validation errors.\n",
    "    bias = np.array(train_losses)\n",
    "    variance = np.array(val_losses) - np.array(train_losses)\n",
    "\n",
    "    # Plotting Variance-Bias Trade-off\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.plot(epochs, bias, label='Bias (Training Loss)')\n",
    "    plt.plot(epochs, variance, label='Variance (Val Loss - Train Loss)')\n",
    "    plt.title('Bias-Variance Trade-off')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Error')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "model = EmergencyEventPredictor(\n",
    "    embedding_module=embedding_module,\n",
    "    embed_dim=64,\n",
    "    num_heads=4,\n",
    "    num_layers=2\n",
    ")\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "num_epochs = 10\n",
    "train_and_evaluate(model, train_loader, val_loader, optimizer, criterion, num_epochs)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0956e1a7d24746f3a072e75d256dd023": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3655ab555c854f0fac30dc887d05a0b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5225edfaad754b54bbe5363ad2cfc4d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "635834afa9b042019823c5081ec8cefa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0956e1a7d24746f3a072e75d256dd023",
      "placeholder": "​",
      "style": "IPY_MODEL_3655ab555c854f0fac30dc887d05a0b6",
      "value": "Computing transition probabilities: 100%"
     }
    },
    "7bdcf4bb5a6e491eb5f29470d14aff6b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8da88441f8c84d5a9a7d8f6ca4526ceb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a173c1ee575742aebe887c7150149fb9",
      "placeholder": "​",
      "style": "IPY_MODEL_d50aee24efa4495ea741fe0d7e132c28",
      "value": " 403/403 [00:00&lt;00:00, 2427.50it/s]"
     }
    },
    "950ff52c23cb4c9a913ee758fc930452": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a173c1ee575742aebe887c7150149fb9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d50aee24efa4495ea741fe0d7e132c28": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ee5563d32cad45e9a94d2316bd206197": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7bdcf4bb5a6e491eb5f29470d14aff6b",
      "max": 403,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5225edfaad754b54bbe5363ad2cfc4d5",
      "value": 403
     }
    },
    "fd9ec72686d240f5b84b9fbbedbfcd73": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_635834afa9b042019823c5081ec8cefa",
       "IPY_MODEL_ee5563d32cad45e9a94d2316bd206197",
       "IPY_MODEL_8da88441f8c84d5a9a7d8f6ca4526ceb"
      ],
      "layout": "IPY_MODEL_950ff52c23cb4c9a913ee758fc930452"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
