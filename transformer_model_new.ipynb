{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\hardy\\documents\\ece2500-safe-city\\venv\\lib\\site-packages (2.1.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\hardy\\documents\\ece2500-safe-city\\venv\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: geopandas in c:\\users\\hardy\\documents\\ece2500-safe-city\\venv\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: torch in c:\\users\\hardy\\documents\\ece2500-safe-city\\venv\\lib\\site-packages (2.5.1)\n",
      "Collecting node2vec\n",
      "  Using cached node2vec-0.5.0-py3-none-any.whl.metadata (849 bytes)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\hardy\\documents\\ece2500-safe-city\\venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hardy\\documents\\ece2500-safe-city\\venv\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\hardy\\documents\\ece2500-safe-city\\venv\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: pyogrio>=0.7.2 in c:\\users\\hardy\\documents\\ece2500-safe-city\\venv\\lib\\site-packages (from geopandas) (0.10.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\hardy\\documents\\ece2500-safe-city\\venv\\lib\\site-packages (from geopandas) (24.2)\n",
      "Requirement already satisfied: pyproj>=3.3.0 in c:\\users\\hardy\\documents\\ece2500-safe-city\\venv\\lib\\site-packages (from geopandas) (3.7.0)\n",
      "Requirement already satisfied: shapely>=2.0.0 in c:\\users\\hardy\\documents\\ece2500-safe-city\\venv\\lib\\site-packages (from geopandas) (2.0.6)\n",
      "Requirement already satisfied: filelock in c:\\users\\hardy\\documents\\ece2500-safe-city\\venv\\lib\\site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\hardy\\documents\\ece2500-safe-city\\venv\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\hardy\\documents\\ece2500-safe-city\\venv\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hardy\\documents\\ece2500-safe-city\\venv\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\hardy\\documents\\ece2500-safe-city\\venv\\lib\\site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hardy\\documents\\ece2500-safe-city\\venv\\lib\\site-packages (from torch) (75.6.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\hardy\\documents\\ece2500-safe-city\\venv\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\hardy\\documents\\ece2500-safe-city\\venv\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Collecting gensim<5.0.0,>=4.3.0 (from node2vec)\n",
      "  Using cached gensim-4.3.3-cp312-cp312-win_amd64.whl.metadata (8.2 kB)\n",
      "Collecting joblib<2.0.0,>=1.4.0 (from node2vec)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting numpy\n",
      "  Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl.metadata (61 kB)\n",
      "Collecting tqdm<5.0.0,>=4.66.1 (from node2vec)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "     ---------------------------------------- 0.0/57.7 kB ? eta -:--:--\n",
      "     --------------------- ------------------ 30.7/57.7 kB 1.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 57.7/57.7 kB 1.5 MB/s eta 0:00:00\n",
      "Collecting scipy<1.14.0,>=1.7.0 (from gensim<5.0.0,>=4.3.0->node2vec)\n",
      "  Using cached scipy-1.13.1-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting smart-open>=1.8.1 (from gensim<5.0.0,>=4.3.0->node2vec)\n",
      "  Using cached smart_open-7.0.5-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: certifi in c:\\users\\hardy\\documents\\ece2500-safe-city\\venv\\lib\\site-packages (from pyogrio>=0.7.2->geopandas) (2024.8.30)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hardy\\documents\\ece2500-safe-city\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\hardy\\documents\\ece2500-safe-city\\venv\\lib\\site-packages (from tqdm<5.0.0,>=4.66.1->node2vec) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hardy\\documents\\ece2500-safe-city\\venv\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Collecting wrapt (from smart-open>=1.8.1->gensim<5.0.0,>=4.3.0->node2vec)\n",
      "  Downloading wrapt-1.17.0-cp312-cp312-win_amd64.whl.metadata (6.5 kB)\n",
      "Using cached node2vec-0.5.0-py3-none-any.whl (7.2 kB)\n",
      "Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl (15.5 MB)\n",
      "Using cached gensim-4.3.3-cp312-cp312-win_amd64.whl (24.0 MB)\n",
      "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "   ---------------------------------------- 0.0/301.8 kB ? eta -:--:--\n",
      "   --------------------------------------- 301.8/301.8 kB 19.4 MB/s eta 0:00:00\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 78.5/78.5 kB ? eta 0:00:00\n",
      "Using cached scipy-1.13.1-cp312-cp312-win_amd64.whl (45.9 MB)\n",
      "Using cached smart_open-7.0.5-py3-none-any.whl (61 kB)\n",
      "Downloading wrapt-1.17.0-cp312-cp312-win_amd64.whl (38 kB)\n",
      "Installing collected packages: wrapt, tqdm, numpy, joblib, smart-open, scipy, gensim, node2vec\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.1.3\n",
      "    Uninstalling numpy-2.1.3:\n",
      "      Successfully uninstalled numpy-2.1.3\n",
      "Successfully installed gensim-4.3.3 joblib-1.4.2 node2vec-0.5.0 numpy-1.26.4 scipy-1.13.1 smart-open-7.0.5 tqdm-4.67.1 wrapt-1.17.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\hardy\\Documents\\ECE2500-safe-city\\venv\\Lib\\site-packages\\~umpy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\hardy\\Documents\\ECE2500-safe-city\\venv\\Lib\\site-packages\\~umpy'.\n",
      "  You can safely remove it manually.\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy pandas geopandas torch node2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip cache purge\n",
    "!pip install numpy==1.22.4 gensim==4.3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PObN0B-3Sk1w"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy.rec'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnetworkx\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnx\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader, Dataset\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnode2vec\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Node2Vec\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mshapely\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeometry\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Point, MultiPolygon\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mshapely\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwkt\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m loads\n",
      "File \u001b[1;32mc:\\Users\\hardy\\Documents\\ECE2500-safe-city\\venv\\Lib\\site-packages\\node2vec\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m edges\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnode2vec\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Node2Vec\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimportlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m metadata\n",
      "File \u001b[1;32mc:\\Users\\hardy\\Documents\\ECE2500-safe-city\\venv\\Lib\\site-packages\\node2vec\\edges.py:7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcheck_gensim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_dated_gensim_version\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KeyedVectors\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mEdgeEmbedder\u001b[39;00m(ABC):\n",
      "File \u001b[1;32mc:\\Users\\hardy\\Documents\\ECE2500-safe-city\\venv\\Lib\\site-packages\\gensim\\__init__.py:11\u001b[0m\n\u001b[0;32m      7\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m4.3.3\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parsing, corpora, matutils, interfaces, models, similarities, utils  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[0;32m     14\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgensim\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m logger\u001b[38;5;241m.\u001b[39mhandlers:  \u001b[38;5;66;03m# To ensure reload() doesn't add another one\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hardy\\Documents\\ECE2500-safe-city\\venv\\Lib\\site-packages\\gensim\\parsing\\__init__.py:4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"This package contains functions to preprocess raw text\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mporter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PorterStemmer  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     preprocess_documents,\n\u001b[0;32m      6\u001b[0m     preprocess_string,\n\u001b[0;32m      7\u001b[0m     read_file,\n\u001b[0;32m      8\u001b[0m     read_files,\n\u001b[0;32m      9\u001b[0m     remove_stopwords,\n\u001b[0;32m     10\u001b[0m     split_alphanum,\n\u001b[0;32m     11\u001b[0m     stem_text,\n\u001b[0;32m     12\u001b[0m     strip_multiple_whitespaces,\n\u001b[0;32m     13\u001b[0m     strip_non_alphanum,\n\u001b[0;32m     14\u001b[0m     strip_numeric,\n\u001b[0;32m     15\u001b[0m     strip_punctuation,\n\u001b[0;32m     16\u001b[0m     strip_short,\n\u001b[0;32m     17\u001b[0m     strip_tags,\n\u001b[0;32m     18\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\hardy\\Documents\\ECE2500-safe-city\\venv\\Lib\\site-packages\\gensim\\parsing\\preprocessing.py:26\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mstring\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mglob\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparsing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mporter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PorterStemmer\n\u001b[0;32m     30\u001b[0m STOPWORDS \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfrozenset\u001b[39m([\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msix\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjust\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mless\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbeing\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindeed\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mover\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmove\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124manyway\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfour\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnot\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mown\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthrough\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124musing\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfifty\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwhere\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmill\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124monly\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfind\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mone\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwhose\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhow\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msomewhere\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmake\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124monce\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     59\u001b[0m ])\n",
      "File \u001b[1;32mc:\\Users\\hardy\\Documents\\ECE2500-safe-city\\venv\\Lib\\site-packages\\gensim\\utils.py:35\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtypes\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msmart_open\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;28mopen\u001b[39m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__ \u001b[38;5;28;01mas\u001b[39;00m gensim_version\n",
      "File \u001b[1;32mc:\\Users\\hardy\\Documents\\ECE2500-safe-city\\venv\\Lib\\site-packages\\scipy\\sparse\\__init__.py:294\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# Original code by Travis Oliphant.\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;66;03m# Modified and extended by Ed Schofield, Robert Cimrman,\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[38;5;66;03m# Nathan Bell, and Jake Vanderplas.\u001b[39;00m\n\u001b[0;32m    292\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_warnings\u001b[39;00m\n\u001b[1;32m--> 294\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m    295\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_csr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m    296\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_csc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\hardy\\Documents\\ECE2500-safe-city\\venv\\Lib\\site-packages\\scipy\\sparse\\_base.py:5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m warn\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_util\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VisibleDeprecationWarning\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_sputils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (asmatrix, check_reshape_kwargs, check_shape,\n\u001b[0;32m      8\u001b[0m                        get_sum_dtype, isdense, isscalarlike,\n\u001b[0;32m      9\u001b[0m                        matrix, validateaxis,)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_matrix\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m spmatrix\n",
      "File \u001b[1;32mc:\\Users\\hardy\\Documents\\ECE2500-safe-city\\venv\\Lib\\site-packages\\scipy\\_lib\\_util.py:18\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     11\u001b[0m     Optional,\n\u001b[0;32m     12\u001b[0m     Union,\n\u001b[0;32m     13\u001b[0m     TYPE_CHECKING,\n\u001b[0;32m     14\u001b[0m     TypeVar,\n\u001b[0;32m     15\u001b[0m )\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_array_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m array_namespace\n\u001b[0;32m     21\u001b[0m AxisError: \u001b[38;5;28mtype\u001b[39m[\u001b[38;5;167;01mException\u001b[39;00m]\n\u001b[0;32m     22\u001b[0m ComplexWarning: \u001b[38;5;28mtype\u001b[39m[\u001b[38;5;167;01mWarning\u001b[39;00m]\n",
      "File \u001b[1;32mc:\\Users\\hardy\\Documents\\ECE2500-safe-city\\venv\\Lib\\site-packages\\scipy\\_lib\\_array_api.py:17\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m array_api_compat\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marray_api_compat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     18\u001b[0m     is_array_api_obj,\n\u001b[0;32m     19\u001b[0m     size,\n\u001b[0;32m     20\u001b[0m     numpy \u001b[38;5;28;01mas\u001b[39;00m np_compat,\n\u001b[0;32m     21\u001b[0m )\n\u001b[0;32m     23\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marray_namespace\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_asarray\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# To enable array API and strict array-like input validation\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hardy\\Documents\\ECE2500-safe-city\\venv\\Lib\\site-packages\\scipy\\_lib\\array_api_compat\\numpy\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# from numpy import * doesn't overwrite these builtin names\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;28mabs\u001b[39m, \u001b[38;5;28mmax\u001b[39m, \u001b[38;5;28mmin\u001b[39m, \u001b[38;5;28mround\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\hardy\\Documents\\ECE2500-safe-city\\venv\\Lib\\site-packages\\numpy\\__init__.py:380\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr)\u001b[0m\n\u001b[0;32m    378\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mabs\u001b[39m(x\u001b[38;5;241m.\u001b[39mdot(x) \u001b[38;5;241m-\u001b[39m float32(\u001b[38;5;241m2.0\u001b[39m)) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1e-5\u001b[39m:\n\u001b[0;32m    379\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m()\n\u001b[1;32m--> 380\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m:\n\u001b[0;32m    381\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe current Numpy installation (\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m) fails to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    382\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpass simple sanity checks. This can be caused for example \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    383\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mby incorrect BLAS library being linked in, or by mixing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    384\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpackage managers (pip, conda, apt, ...). Search closed \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    385\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy issues for similar problems.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    386\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;18m__file__\u001b[39m)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numpy.rec'"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import networkx as nx\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from gensim.models import KeyedVectors\n",
    "from node2vec import Node2Vec\n",
    "from shapely.geometry import Point, MultiPolygon\n",
    "from shapely.wkt import loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Dataset Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Running locally, reading dataset from local file system\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hardy\\AppData\\Local\\Temp\\ipykernel_21392\\998725363.py:23: DtypeWarning: Columns (12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  unit_trip_df = pd.read_csv(UNIT_TRIP_PATH)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  from google.colab import drive\n",
    "  logger.info(\"Running on Google Colab, reading dataset from drive\")\n",
    "  drive.mount(\"/content/drive\")\n",
    "  DATASET_PATH = \"/content/drive/MyDrive/ECE2500/EdmontonFireRescueServicesData\"\n",
    "except:\n",
    "  logger.info(\"Running locally, reading dataset from local file system\")\n",
    "  DATASET_PATH = \"./dataset/EdmontonFireRescueServicesData\"\n",
    "  if not os.path.exists(DATASET_PATH):\n",
    "    logger.critical(f\"Cannot find dataset directory, place dataset in {DATASET_PATH}\")\n",
    "    exit(1)\n",
    "\n",
    "UNIT_TRIP_PATH = os.path.join(DATASET_PATH, \"EFRS_Unit_Trip_Summary.csv\")\n",
    "WEEKLY_EVENTS_PATH = os.path.join(DATASET_PATH, \"weekly_events.csv\")\n",
    "NEIGHBOURHOOD_PATH = os.path.join(DATASET_PATH, \"City_of_Edmonton_-_Neighbourhoods_20241022.csv\")\n",
    "NEIGHBOURHOOD_FEATURES_PATH = os.path.join(DATASET_PATH, \"neighbourhood_features.csv\")\n",
    "\n",
    "logger.debug(f\"Unit Trip: {UNIT_TRIP_PATH}\")\n",
    "logger.debug(f\"Weekly Events: {WEEKLY_EVENTS_PATH}\")\n",
    "logger.debug(f\"Neighbourhood: {NEIGHBOURHOOD_PATH}\")\n",
    "logger.debug(f\"Neighbourhood Features: {NEIGHBOURHOOD_FEATURES_PATH}\")\n",
    "\n",
    "unit_trip_df = pd.read_csv(UNIT_TRIP_PATH)\n",
    "weekly_events_df = pd.read_csv(WEEKLY_EVENTS_PATH)\n",
    "neighbourhood_df = pd.read_csv(NEIGHBOURHOOD_PATH)\n",
    "neighbourhood_feature_df = pd.read_csv(NEIGHBOURHOOD_FEATURES_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fpSHJ3I6onMQ"
   },
   "source": [
    "**Data and Embedding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vkOrdiUYoiTw"
   },
   "outputs": [],
   "source": [
    "def generate_node2vec_embeddings(neighbourhood_info_df, node2vec_dim=32):\n",
    "  \"\"\"\n",
    "  Generates Node2Vec embeddings for neighborhoods based on a sample adjacency graph.\n",
    "  node2vec_dim: Dimension of the embeddings to be generated.\n",
    "  \"\"\"\n",
    "\n",
    "  num_neighborhood_info = len(neighbourhood_info_df)\n",
    "  G = nx.Graph()\n",
    "\n",
    "  # Convert \"Geometry Multipolygon\" column to GeoSeries\n",
    "  neighbourhood_info_df['geometry'] = gpd.GeoSeries.from_wkt(neighbourhood_info_df['Geometry Multipolygon'])\n",
    "  neighbourhood_info_df['nid'] = range(num_neighborhood_info)\n",
    "\n",
    "  # Assuming you have a way to define neighborhood connections based on proximity\n",
    "  # You can use the geometry information for this.\n",
    "  # Here's a placeholder for how you might connect neighborhoods based on proximity:\n",
    "\n",
    "  for i in range(num_neighborhood_info):\n",
    "    for j in range(i + 1, num_neighborhood_info):\n",
    "      # Use the new 'geometry' column for spatial operations\n",
    "      if neighbourhood_info_df['geometry'].iloc[i].intersects(neighbourhood_info_df['geometry'].iloc[j]):\n",
    "        G.add_edge(i, j)\n",
    "\n",
    "  # Alternatively, you could build a graph based on other criteria like sharing a boundary\n",
    "  node2vec = Node2Vec(G, dimensions=node2vec_dim, walk_length=10, num_walks=100, p=1, q=1)\n",
    "  node2vec_model = node2vec.fit()\n",
    "  node2vec_embeddings_np = np.array([node2vec_model.wv[str(i)] for i in range(num_neighborhood_info)])\n",
    "  node2vec_embeddings = torch.from_numpy(node2vec_embeddings_np)\n",
    "  node2vec_emb_layer = nn.Embedding.from_pretrained(node2vec_embeddings, freeze=True)\n",
    "\n",
    "  return node2vec_emb_layer\n",
    "\n",
    "\n",
    "class Time2Vec(nn.Module):\n",
    "  \"\"\"\n",
    "  Time2Vec embedding module for temporal features\n",
    "\n",
    "  This captures both linear and periodic components for time-based features.\n",
    "  \"\"\"\n",
    "  def __init__(self, input_dim, embed_dim, act_function=torch.sin):\n",
    "    super(Time2Vec, self).__init__()\n",
    "    self.embed_dim = embed_dim // input_dim  # Embedding dimension per time feature\n",
    "    self.act_function = act_function       # Activation function for periodicity\n",
    "    self.weight = nn.Parameter(torch.randn(input_dim, self.embed_dim))\n",
    "    self.bias = nn.Parameter(torch.randn(input_dim, self.embed_dim))\n",
    "\n",
    "  def forward(self, x):\n",
    "    # Diagonal embedding for each time feature (day of week, hour, etc.)\n",
    "    x = torch.diag_embed(x)\n",
    "    x_affine = torch.matmul(x, self.weight) + self.bias\n",
    "    x_affine_0, x_affine_remain = torch.split(x_affine, [1, self.embed_dim - 1], dim=-1)\n",
    "    x_affine_remain = self.act_function(x_affine_remain)\n",
    "    return torch.cat([x_affine_0, x_affine_remain], dim=-1).view(x.size(0), x.size(1), -1)\n",
    "\n",
    "\n",
    "class NeighborhoodDataset(Dataset):\n",
    "    def __init__(self, neighborhood_ids, time_features, building_type_ids, building_counts,\n",
    "                 population, event_type_ids, equipment_ids, targets):\n",
    "        self.neighborhood_ids = neighborhood_ids  # Tensor of input neighborhood_ids\n",
    "        self.time_features = time_features  # Tensor of input time_features\n",
    "        self.building_type_ids = building_type_ids  # Tensor of input building_type_ids\n",
    "        self.building_counts = building_counts  # Tensor of input building_counts\n",
    "        self.population = population  # Tensor of input population\n",
    "        self.event_type_ids = event_type_ids  # Tensor of input event_type_ids\n",
    "        self.equipment_ids = equipment_ids  # Tensor of input equipment_ids\n",
    "        self.targets = targets    # Tensor of target values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.neighborhood_ids)  # Number of neighborhoods\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.neighborhood_ids[idx], self.time_features[idx], self.building_type_ids[idx], self.building_counts[idx],\n",
    "                self.population[idx], self.event_type_ids[idx], self.equipment_ids[idx], self.targets[idx])\n",
    "\n",
    "\n",
    "class CombinedEmbedding(nn.Module):\n",
    "  \"\"\"\n",
    "  Combined Embedding Module\n",
    "\n",
    "  Combines embeddings from Node2Vec, Time2Vec, building type/counts, population, event type, and equipment.\n",
    "  Projects the combined embedding to a target dimension (e.g., 64) for compatibility with transformer layers.\n",
    "  \"\"\"\n",
    "  def __init__(self, node2vec_emb_layer, time2vec_embed_dim, time_feature_dim,\n",
    "          num_building_types, building_type_embed_dim, population_embed_dim,\n",
    "          num_event_types, event_type_embed_dim, num_equipment_types, equipment_embed_dim,\n",
    "          target_embed_dim=64):  # Add target_embed_dim for projection\n",
    "    super(CombinedEmbedding, self).__init__()\n",
    "\n",
    "    # Embedding initialization code\n",
    "    self.node2vec_emb_layer = node2vec_emb_layer  # Precomputed Node2Vec embeddings\n",
    "    self.time2vec = Time2Vec(input_dim=time_feature_dim, embed_dim=time2vec_embed_dim)\n",
    "    self.building_type_embedding = nn.Embedding(num_building_types, building_type_embed_dim)\n",
    "    self.population_embedding = nn.Linear(1, population_embed_dim)\n",
    "    self.event_type_embedding = nn.Embedding(num_event_types, event_type_embed_dim)\n",
    "    self.equipment_embedding = nn.Embedding(num_equipment_types, equipment_embed_dim)\n",
    "\n",
    "    # Compute the combined embedding dimension before projection\n",
    "    # num_neighbourhood * 2 (month + year) * x\n",
    "    self.projection_dim = (node2vec_emb_layer.embedding_dim + time2vec_embed_dim +\n",
    "                    building_type_embed_dim + population_embed_dim +\n",
    "                    event_type_embed_dim + equipment_embed_dim)\n",
    "\n",
    "    # Projection layer to reduce to target_embed_dim\n",
    "    self.projection_layer = nn.Linear(self.projection_dim, target_embed_dim)\n",
    "    \n",
    "  def forward(self, neighborhood_ids, time_features, building_type_ids, building_counts,\n",
    "            population, event_type_ids, equipment_ids):\n",
    "    # Generate embeddings\n",
    "    spatial_embeddings = self.node2vec_emb_layer(neighborhood_ids).unsqueeze(1).repeat(1, time_features.size(1), 1)\n",
    "    logger.debug(f\"Spatial Embedding Shape: {spatial_embeddings.shape}\")\n",
    "\n",
    "    temporal_embeddings = self.time2vec(time_features)\n",
    "    logger.debug(f\"Temporal Embedding Shape: {temporal_embeddings.shape}\")\n",
    "\n",
    "    #building_embeddings = (self.building_type_embedding(building_type_ids) * building_counts).sum(dim=2)\n",
    "    #building_embeddings = building_embeddings.unsqueeze(1).repeat(1, time_features.size(1), 1)\n",
    "    #logger.debug(f\"Building Embedding Shape: {building_embeddings.shape}\")\n",
    "    \n",
    "    \n",
    "    # Building embeddings\n",
    "    building_type_embeds = self.building_type_embedding(building_type_ids)  # Shape: [batch_size, num_building_types, building_type_embed_dim]\n",
    "    logger.debug(f\"Building Type Embeds Shape: {building_type_embeds.shape}\")\n",
    "\n",
    "    # Adjust building_counts to match building_type_embed_dim\n",
    "    building_counts = building_counts.unsqueeze(-1)  # Shape: [batch_size, 1, num_building_types, 1]\n",
    "    building_counts = building_counts.repeat(1, 1, 1, self.building_type_embedding.embedding_dim)  # Match embed_dim\n",
    "    logger.debug(f\"Building Counts Shape after adjustment: {building_counts.shape}\")\n",
    "\n",
    "    # Multiply and aggregate\n",
    "    building_embeddings = (building_type_embeds.unsqueeze(1) * building_counts).sum(dim=2)  # Shape: [batch_size, 1, building_type_embed_dim]\n",
    "    building_embeddings = building_embeddings.repeat(1, time_features.size(1), 1)  # Match temporal dimension\n",
    "    logger.debug(f\"Building Embedding Shape: {building_embeddings.shape}\")\n",
    "\n",
    "    population_embeddings = self.population_embedding(population.unsqueeze(-1)).unsqueeze(1).repeat(1, time_features.size(1), 1)\n",
    "    logger.debug(f\"Population Embedding Shape: {population_embeddings.shape}\")\n",
    "\n",
    "    event_type_embeddings = self.event_type_embedding(event_type_ids)\n",
    "    logger.debug(f\"Event Type Embedding Shape: {event_type_embeddings.shape}\")\n",
    "\n",
    "    equipment_embeddings = self.equipment_embedding(equipment_ids)\n",
    "    logger.debug(f\"Equipment Embedding Shape: {equipment_embeddings.shape}\")\n",
    "\n",
    "    # Concatenate all embeddings\n",
    "    combined_embedding = torch.cat([spatial_embeddings, temporal_embeddings, building_embeddings,\n",
    "                                     population_embeddings, event_type_embeddings, equipment_embeddings], dim=-1)\n",
    "    logger.debug(f\"Combined Embedding Shape before Projection: {combined_embedding.shape}\")\n",
    "\n",
    "    # Project to target dimension\n",
    "    combined_embedding = self.projection_layer(combined_embedding)\n",
    "    return combined_embedding\n",
    "\n",
    "  \"\"\"\n",
    "  def forward(self, neighborhood_ids, time_features, building_type_ids, building_counts,\n",
    "              population, event_type_ids, equipment_ids):\n",
    "    # Generate and combine embeddings\n",
    "    temporal_embeddings = self.time2vec(time_features)\n",
    "    logger.debug(f\"Temporal Embedding Shape: {temporal_embeddings.shape}\")\n",
    "    # Albert: spatial_embeddings = self.node2vec_emb_layer(neighborhood_ids).unsqueeze(1).repeat(1, temporal_embeddings.size(1), 1) # [batch_size, temporal_dimensions, time2vec_embed_dim]\n",
    "    \n",
    "    logger.debug(f\"Spatial Embedding Shape: {spatial_embeddings.shape}\")\n",
    "    building_embeddings = (self.building_type_embedding(building_type_ids) * building_counts.unsqueeze(-1)).sum(dim=2)\n",
    "    logger.debug(f\"Building Embedding Shape: {building_embeddings.shape}\")\n",
    "    population_embeddings = self.population_embedding(population.unsqueeze(-1)).unsqueeze(1).expand(-1, spatial_embeddings.size(1), -1)\n",
    "    logger.debug(f\"Population Embedding Shape: {population_embeddings.shape}\")\n",
    "    event_type_embeddings = self.event_type_embedding(event_type_ids)\n",
    "    logger.debug(f\"Event Type Embedding Shape: {event_type_embeddings.shape}\")\n",
    "    equipment_embeddings = self.equipment_embedding(equipment_ids)\n",
    "    logger.debug(f\"Equipment Embedding Shape: {equipment_embeddings.shape}\")\n",
    "\n",
    "    # Concatenate all embeddings into a single combined embedding\n",
    "    combined_embedding = torch.cat([spatial_embeddings, temporal_embeddings,\n",
    "                                    building_embeddings, population_embeddings,\n",
    "                                    event_type_embeddings, equipment_embeddings], dim=-1)\n",
    "\n",
    "    logger.debug(f\"Combined Embedding Shape before Projection: {combined_embedding.shape}\")\n",
    "\n",
    "    # Project to target dimension for compatibility (e.g., 64)\n",
    "    combined_embedding = self.projection_layer(combined_embedding)\n",
    "\n",
    "    return combined_embedding\n",
    "  \"\"\"\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "  \"\"\"\n",
    "  Positional Encoding Module\n",
    "  \"\"\"\n",
    "  def __init__(self, embed_dim, max_len=7):  # 7 days in a week\n",
    "    super(PositionalEncoding, self).__init__()\n",
    "    position = torch.arange(0, max_len).unsqueeze(1)\n",
    "    div_term = torch.exp(torch.arange(0, embed_dim, 2) * -(math.log(10000.0) / embed_dim))\n",
    "    pe = torch.zeros(max_len, embed_dim)\n",
    "    pe[:, 0::2] = torch.sin(position * div_term)\n",
    "    pe[:, 1::2] = torch.cos(position * div_term)\n",
    "    self.pe = pe.unsqueeze(0)  # Shape: (1, max_len, embed_dim)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = x + self.pe[:, :x.size(1), :].to(x.device)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5mZCuFUYtYpm"
   },
   "source": [
    "**Transformer Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p3CHjlqytU2a"
   },
   "outputs": [],
   "source": [
    "# Transformer-based Emergency Event Predictor\n",
    "class EmergencyEventPredictor(nn.Module):\n",
    "  def __init__(self, embedding_module, embed_dim, num_heads, num_layers, max_len=7):\n",
    "    super(EmergencyEventPredictor, self).__init__()\n",
    "\n",
    "    # Embedding module (CombinedEmbedding) and positional encoding\n",
    "    self.embedding_module = embedding_module\n",
    "    self.positional_encoding = PositionalEncoding(embed_dim, max_len)\n",
    "\n",
    "    # Transformer Encoder\n",
    "    encoder_layer = nn.TransformerEncoderLayer(\n",
    "        d_model=embed_dim, nhead=num_heads, dim_feedforward=512, dropout=0.1\n",
    "    )\n",
    "    self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "    # Prediction head\n",
    "    self.fc_out = nn.Linear(embed_dim, 1)  # Output: predicting the number of events\n",
    "\n",
    "  def forward(self, neighborhood_ids, time_features, building_type_ids, building_counts,\n",
    "              population, event_type_ids, equipment_ids):\n",
    "\n",
    "    # Generate combined embeddings from the embedding module\n",
    "    x = self.embedding_module(neighborhood_ids, time_features, building_type_ids, building_counts,\n",
    "                              population, event_type_ids, equipment_ids)\n",
    "\n",
    "    # Apply positional encoding\n",
    "    x = self.positional_encoding(x)\n",
    "\n",
    "    # Pass through transformer encoder\n",
    "    x = self.transformer_encoder(x)\n",
    "\n",
    "    # Prediction layer (we apply it to each element in the sequence)\n",
    "    # Albert: predictions = self.fc_out(x).squeeze(-1)  # Shape: [batch_size]\n",
    "    predictions = self.fc_out(x.squeeze(1)).squeeze(-1)  # Shape: [batch_size]\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Extraction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_type_list = [\n",
    "    'Apartment_Condo_1_to_4_stories', 'Apartment_Condo_5_or_more_stories',\n",
    "    'Duplex_Fourplex', 'Hotel_Motel',\n",
    "    'Institution_Collective_Residence', 'Manufactured_Mobile_Home',\n",
    "    'RV_Tent_Other', 'Row_House',\n",
    "    'Single_Detached_House'\n",
    "    ]\n",
    "event_type_list = weekly_events_df['Rc_description'].unique()\n",
    "unit_type_list = unit_trip_df['unityp'].unique()\n",
    "\n",
    "num_neighborhoods = len(neighbourhood_feature_df)\n",
    "num_building_types = len(build_type_list)\n",
    "num_event_types = len(event_type_list)\n",
    "num_equipment_types = len(unit_type_list)\n",
    "\n",
    "neighbourhood_mappings = weekly_events_df[\"Neighbourhood Number\"].unique()\n",
    "building_counts_np = neighbourhood_feature_df[build_type_list].fillna(0).astype(int).to_numpy()\n",
    "population_np = neighbourhood_feature_df['Population'].fillna(0).astype(int).to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transformer Model Initalization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AEKcsqMG3l9T",
    "outputId": "71924b64-6378-4397-e650-8fc33a4f8b57"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "413b7dd3518f4acaa1ee1c59dd05a31a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/403 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 1): 100%|██████████| 100/100 [00:01<00:00, 82.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:collecting all words and their counts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #10000, processed 100000 words, keeping 403 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #20000, processed 200000 words, keeping 403 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #30000, processed 300000 words, keeping 403 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #40000, processed 400000 words, keeping 403 word types\n",
      "INFO:gensim.models.word2vec:collected 403 word types from a corpus of 403000 raw words and 40300 sentences\n",
      "INFO:gensim.models.word2vec:Creating a fresh vocabulary\n",
      "INFO:gensim.utils:Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 403 unique words (100.00% of original 403, drops 0)', 'datetime': '2024-11-25T02:15:00.397766', 'gensim': '4.3.3', 'python': '3.12.4 | packaged by Anaconda, Inc. | (main, Jun 18 2024, 15:03:56) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'prepare_vocab'}\n",
      "INFO:gensim.utils:Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 403000 word corpus (100.00% of original 403000, drops 0)', 'datetime': '2024-11-25T02:15:00.398763', 'gensim': '4.3.3', 'python': '3.12.4 | packaged by Anaconda, Inc. | (main, Jun 18 2024, 15:03:56) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'prepare_vocab'}\n",
      "INFO:gensim.models.word2vec:deleting the raw counts dictionary of 403 items\n",
      "INFO:gensim.models.word2vec:sample=0.001 downsamples 151 most-common words\n",
      "INFO:gensim.utils:Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 381344.08350731217 word corpus (94.6%% of prior 403000)', 'datetime': '2024-11-25T02:15:00.407220', 'gensim': '4.3.3', 'python': '3.12.4 | packaged by Anaconda, Inc. | (main, Jun 18 2024, 15:03:56) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'prepare_vocab'}\n",
      "INFO:gensim.models.word2vec:estimated required memory for 403 words and 32 dimensions: 304668 bytes\n",
      "INFO:gensim.models.word2vec:resetting layer weights\n",
      "INFO:gensim.utils:Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-11-25T02:15:00.412574', 'gensim': '4.3.3', 'python': '3.12.4 | packaged by Anaconda, Inc. | (main, Jun 18 2024, 15:03:56) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'build_vocab'}\n",
      "INFO:gensim.utils:Word2Vec lifecycle event {'msg': 'training model with 1 workers on 403 vocabulary and 32 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-11-25T02:15:00.413574', 'gensim': '4.3.3', 'python': '3.12.4 | packaged by Anaconda, Inc. | (main, Jun 18 2024, 15:03:56) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'train'}\n",
      "INFO:gensim.models.word2vec:EPOCH 0: training on 403000 raw words (381116 effective words) took 0.7s, 563766 effective words/s\n",
      "INFO:gensim.models.word2vec:EPOCH 1: training on 403000 raw words (381568 effective words) took 0.6s, 604752 effective words/s\n",
      "INFO:gensim.models.word2vec:EPOCH 2: training on 403000 raw words (381165 effective words) took 0.6s, 625257 effective words/s\n",
      "INFO:gensim.models.word2vec:EPOCH 3: training on 403000 raw words (381434 effective words) took 0.6s, 630716 effective words/s\n",
      "INFO:gensim.models.word2vec:EPOCH 4: training on 403000 raw words (381501 effective words) took 0.6s, 614062 effective words/s\n",
      "INFO:gensim.utils:Word2Vec lifecycle event {'msg': 'training on 2015000 raw words (1906784 effective words) took 3.2s, 602410 effective words/s', 'datetime': '2024-11-25T02:15:03.578937', 'gensim': '4.3.3', 'python': '3.12.4 | packaged by Anaconda, Inc. | (main, Jun 18 2024, 15:03:56) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'train'}\n",
      "INFO:gensim.utils:Word2Vec lifecycle event {'params': 'Word2Vec<vocab=403, vector_size=32, alpha=0.025>', 'datetime': '2024-11-25T02:15:03.578937', 'gensim': '4.3.3', 'python': '3.12.4 | packaged by Anaconda, Inc. | (main, Jun 18 2024, 15:03:56) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "# Embedding Parameter and Module\n",
    "\n",
    "node2vec_dim = 32\n",
    "time2vec_embed_dim = 64\n",
    "time_feature_dim = 2  # week, year\n",
    "building_type_embed_dim = 16\n",
    "population_embed_dim = 8\n",
    "event_type_embed_dim = 16\n",
    "equipment_embed_dim = 16\n",
    "target_embed_dim = 64\n",
    "\n",
    "node2vec_emb_layer = generate_node2vec_embeddings(\n",
    "    neighbourhood_info_df=neighbourhood_df,\n",
    "    node2vec_dim=node2vec_dim\n",
    ")\n",
    "\n",
    "embedding_module = CombinedEmbedding(\n",
    "    node2vec_emb_layer=node2vec_emb_layer,\n",
    "    time2vec_embed_dim=time2vec_embed_dim,\n",
    "    time_feature_dim=time_feature_dim,\n",
    "    num_building_types=num_building_types,\n",
    "    building_type_embed_dim=building_type_embed_dim,\n",
    "    population_embed_dim=population_embed_dim,\n",
    "    num_event_types=num_event_types,\n",
    "    event_type_embed_dim=event_type_embed_dim,\n",
    "    num_equipment_types=num_equipment_types,\n",
    "    equipment_embed_dim=equipment_embed_dim,\n",
    "    target_embed_dim=target_embed_dim\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define batch and mini-batch\n",
    "\n",
    "mini_batch_size = 29\n",
    "batch_size = 13\n",
    "\n",
    "spatial_dimension = num_neighborhoods\n",
    "\n",
    "# verify spatial_dimension = batch_size * mini_batch_size\n",
    "assert spatial_dimension == batch_size * mini_batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:__main__:neighborhood_ids shape torch.Size([377])\n",
      "INFO:__main__:time_features shape: torch.Size([377, 1, 2])\n",
      "INFO:__main__:building_type_ids shape torch.Size([377, 9])\n",
      "INFO:__main__:building_counts shape torch.Size([377, 1, 9])\n",
      "INFO:__main__:population shape torch.Size([377])\n",
      "INFO:__main__:event_type_ids shape torch.Size([377])\n",
      "INFO:__main__:equipment_ids shape torch.Size([377])\n",
      "INFO:__main__:targets shape torch.Size([377, 623])\n"
     ]
    }
   ],
   "source": [
    "# Neighborhood Features\n",
    "neighborhood_ids = torch.arange(num_neighborhoods)\n",
    "logger.info(f\"neighborhood_ids shape {neighborhood_ids.shape}\")\n",
    "\n",
    "# Time Feature\n",
    "time_features = torch.zeros(spatial_dimension, 1, time_feature_dim)\n",
    "for nid in range(num_neighborhoods):\n",
    "    neighborhood_data = weekly_events_df[weekly_events_df[\"Neighbourhood Number\"] == neighbourhood_mappings[nid]]\n",
    "    if not neighborhood_data.empty:\n",
    "        year_mean = neighborhood_data[\"year\"].mean()\n",
    "        week_mean = neighborhood_data[\"week_of_year\"].mean()\n",
    "        time_features[nid, 0, :] = torch.tensor([year_mean, week_mean])\n",
    "    else:\n",
    "        time_features[nid, 0, :] = torch.zeros(time_feature_dim)\n",
    "logger.info(f\"time_features shape: {time_features.shape}\")\n",
    "\n",
    "# Building Features\n",
    "building_type_ids = torch.arange(num_building_types).repeat(spatial_dimension, 1)\n",
    "logger.info(f\"building_type_ids shape {building_type_ids.shape}\")\n",
    "\n",
    "building_counts_np = neighbourhood_feature_df[build_type_list].fillna(0).to_numpy(dtype=np.int32)\n",
    "temporal_dimension = 1\n",
    "building_counts = torch.from_numpy(building_counts_np).unsqueeze(1).repeat(1, temporal_dimension, 1)\n",
    "logger.info(f\"building_counts shape {building_counts.shape}\")\n",
    "\n",
    "# Demographic Features\n",
    "population = torch.from_numpy(population_np).float()\n",
    "logger.info(f\"population shape {population.shape}\")\n",
    "\n",
    "# Event Features\n",
    "event_type_ids = torch.randint(0, num_event_types, (spatial_dimension,))\n",
    "logger.info(f\"event_type_ids shape {event_type_ids.shape}\")\n",
    "\n",
    "equipment_ids = torch.randint(0, num_equipment_types, (spatial_dimension,))\n",
    "logger.info(f\"equipment_ids shape {equipment_ids.shape}\")\n",
    "\n",
    "# Target Values\n",
    "agg_data = weekly_events_df.groupby(['year', 'week_of_year', 'Neighbourhood Number']).agg({\n",
    "    'Rc_description': ' '.join,\n",
    "    'event_count': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "unique_week_year_combinations = agg_data[['year', 'week_of_year']].drop_duplicates()\n",
    "num_combinations = len(unique_week_year_combinations)\n",
    "\n",
    "targets = torch.zeros((num_neighborhoods, num_combinations), dtype=torch.float32)\n",
    "for i, neighbourhood in enumerate(neighbourhood_feature_df['Neighbourhood_Number']):\n",
    "    neighbourhood_data = agg_data[agg_data['Neighbourhood Number'] == neighbourhood]\n",
    "    for k, (year, week) in enumerate(unique_week_year_combinations.itertuples(index=False)):\n",
    "        event_count = neighbourhood_data[(neighbourhood_data['year'] == year) &\n",
    "                                         (neighbourhood_data['week_of_year'] == week)]['event_count'].sum() or 0\n",
    "        targets[i, k] = event_count\n",
    "logger.info(f\"targets shape {targets.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dutQ0WcSgki5"
   },
   "source": [
    "**Transformer Model Training Loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:__main__:neighborhood_ids shape torch.Size([377])\n",
      "INFO:__main__:time_features shape: torch.Size([377, 1, 2])\n",
      "INFO:__main__:building_type_ids shape torch.Size([377, 9])\n",
      "INFO:__main__:building_counts shape torch.Size([377, 1, 9])\n",
      "INFO:__main__:population shape torch.Size([377])\n",
      "INFO:__main__:event_type_ids shape torch.Size([377, 1])\n",
      "INFO:__main__:equipment_ids shape torch.Size([377, 1])\n",
      "INFO:__main__:targets shape torch.Size([377])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hardy\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Epoch [1/10], Mini-batch [1/13], Loss: 1.3755\n",
      "INFO:__main__:Epoch [1/10], Mini-batch [2/13], Loss: 1.2624\n",
      "INFO:__main__:Epoch [1/10], Mini-batch [3/13], Loss: 0.7101\n",
      "INFO:__main__:Epoch [1/10], Mini-batch [4/13], Loss: 1.2983\n",
      "INFO:__main__:Epoch [1/10], Mini-batch [5/13], Loss: 0.6656\n",
      "INFO:__main__:Epoch [1/10], Mini-batch [6/13], Loss: 2.6776\n",
      "INFO:__main__:Epoch [1/10], Mini-batch [7/13], Loss: 0.9738\n",
      "INFO:__main__:Epoch [1/10], Mini-batch [8/13], Loss: 0.7871\n",
      "INFO:__main__:Epoch [1/10], Mini-batch [9/13], Loss: 0.7652\n",
      "INFO:__main__:Epoch [1/10], Mini-batch [10/13], Loss: 0.9051\n",
      "INFO:__main__:Epoch [1/10], Mini-batch [11/13], Loss: 0.8812\n",
      "INFO:__main__:Epoch [1/10], Mini-batch [12/13], Loss: 0.7460\n",
      "INFO:__main__:Epoch [1/10], Mini-batch [13/13], Loss: 0.8881\n",
      "INFO:__main__:Epoch [1/10] completed, Average Loss: 1.0720\n",
      "INFO:__main__:Epoch [2/10], Mini-batch [1/13], Loss: 1.0434\n",
      "INFO:__main__:Epoch [2/10], Mini-batch [2/13], Loss: 0.6806\n",
      "INFO:__main__:Epoch [2/10], Mini-batch [3/13], Loss: 0.6421\n",
      "INFO:__main__:Epoch [2/10], Mini-batch [4/13], Loss: -0.1521\n",
      "INFO:__main__:Epoch [2/10], Mini-batch [5/13], Loss: 0.3951\n",
      "INFO:__main__:Epoch [2/10], Mini-batch [6/13], Loss: 0.6070\n",
      "INFO:__main__:Epoch [2/10], Mini-batch [7/13], Loss: 0.3597\n",
      "INFO:__main__:Epoch [2/10], Mini-batch [8/13], Loss: 0.8931\n",
      "INFO:__main__:Epoch [2/10], Mini-batch [9/13], Loss: 0.6687\n",
      "INFO:__main__:Epoch [2/10], Mini-batch [10/13], Loss: 0.6405\n",
      "INFO:__main__:Epoch [2/10], Mini-batch [11/13], Loss: 1.3391\n",
      "INFO:__main__:Epoch [2/10], Mini-batch [12/13], Loss: 0.8628\n",
      "INFO:__main__:Epoch [2/10], Mini-batch [13/13], Loss: 0.9435\n",
      "INFO:__main__:Epoch [2/10] completed, Average Loss: 0.6864\n",
      "INFO:__main__:Epoch [3/10], Mini-batch [1/13], Loss: 0.6645\n",
      "INFO:__main__:Epoch [3/10], Mini-batch [2/13], Loss: 0.7490\n",
      "INFO:__main__:Epoch [3/10], Mini-batch [3/13], Loss: 0.8332\n",
      "INFO:__main__:Epoch [3/10], Mini-batch [4/13], Loss: 0.7268\n",
      "INFO:__main__:Epoch [3/10], Mini-batch [5/13], Loss: 1.1750\n",
      "INFO:__main__:Epoch [3/10], Mini-batch [6/13], Loss: 0.9744\n",
      "INFO:__main__:Epoch [3/10], Mini-batch [7/13], Loss: -0.9336\n",
      "INFO:__main__:Epoch [3/10], Mini-batch [8/13], Loss: 0.9986\n",
      "INFO:__main__:Epoch [3/10], Mini-batch [9/13], Loss: 0.9406\n",
      "INFO:__main__:Epoch [3/10], Mini-batch [10/13], Loss: 0.8538\n",
      "INFO:__main__:Epoch [3/10], Mini-batch [11/13], Loss: 0.6862\n",
      "INFO:__main__:Epoch [3/10], Mini-batch [12/13], Loss: 0.6581\n",
      "INFO:__main__:Epoch [3/10], Mini-batch [13/13], Loss: 0.5388\n",
      "INFO:__main__:Epoch [3/10] completed, Average Loss: 0.6820\n",
      "INFO:__main__:Epoch [4/10], Mini-batch [1/13], Loss: 0.6025\n",
      "INFO:__main__:Epoch [4/10], Mini-batch [2/13], Loss: 0.7981\n",
      "INFO:__main__:Epoch [4/10], Mini-batch [3/13], Loss: 0.7632\n",
      "INFO:__main__:Epoch [4/10], Mini-batch [4/13], Loss: 0.6787\n",
      "INFO:__main__:Epoch [4/10], Mini-batch [5/13], Loss: 0.8681\n",
      "INFO:__main__:Epoch [4/10], Mini-batch [6/13], Loss: 0.8349\n",
      "INFO:__main__:Epoch [4/10], Mini-batch [7/13], Loss: 0.6901\n",
      "INFO:__main__:Epoch [4/10], Mini-batch [8/13], Loss: 1.0516\n",
      "INFO:__main__:Epoch [4/10], Mini-batch [9/13], Loss: 0.8011\n",
      "INFO:__main__:Epoch [4/10], Mini-batch [10/13], Loss: 0.6789\n",
      "INFO:__main__:Epoch [4/10], Mini-batch [11/13], Loss: -0.7859\n",
      "INFO:__main__:Epoch [4/10], Mini-batch [12/13], Loss: 0.8338\n",
      "INFO:__main__:Epoch [4/10], Mini-batch [13/13], Loss: 0.7211\n",
      "INFO:__main__:Epoch [4/10] completed, Average Loss: 0.6566\n",
      "INFO:__main__:Epoch [5/10], Mini-batch [1/13], Loss: 0.2937\n",
      "INFO:__main__:Epoch [5/10], Mini-batch [2/13], Loss: 0.7592\n",
      "INFO:__main__:Epoch [5/10], Mini-batch [3/13], Loss: 0.8868\n",
      "INFO:__main__:Epoch [5/10], Mini-batch [4/13], Loss: 0.8558\n",
      "INFO:__main__:Epoch [5/10], Mini-batch [5/13], Loss: 0.7165\n",
      "INFO:__main__:Epoch [5/10], Mini-batch [6/13], Loss: 0.5621\n",
      "INFO:__main__:Epoch [5/10], Mini-batch [7/13], Loss: 0.8223\n",
      "INFO:__main__:Epoch [5/10], Mini-batch [8/13], Loss: 0.8332\n",
      "INFO:__main__:Epoch [5/10], Mini-batch [9/13], Loss: 0.7147\n",
      "INFO:__main__:Epoch [5/10], Mini-batch [10/13], Loss: 0.3877\n",
      "INFO:__main__:Epoch [5/10], Mini-batch [11/13], Loss: 0.8056\n",
      "INFO:__main__:Epoch [5/10], Mini-batch [12/13], Loss: -0.4453\n",
      "INFO:__main__:Epoch [5/10], Mini-batch [13/13], Loss: 0.7962\n",
      "INFO:__main__:Epoch [5/10] completed, Average Loss: 0.6145\n",
      "INFO:__main__:Epoch [6/10], Mini-batch [1/13], Loss: 0.7553\n",
      "INFO:__main__:Epoch [6/10], Mini-batch [2/13], Loss: 0.9557\n",
      "INFO:__main__:Epoch [6/10], Mini-batch [3/13], Loss: 0.8261\n",
      "INFO:__main__:Epoch [6/10], Mini-batch [4/13], Loss: 0.8218\n",
      "INFO:__main__:Epoch [6/10], Mini-batch [5/13], Loss: -1.1450\n",
      "INFO:__main__:Epoch [6/10], Mini-batch [6/13], Loss: 0.8004\n",
      "INFO:__main__:Epoch [6/10], Mini-batch [7/13], Loss: 0.8309\n",
      "INFO:__main__:Epoch [6/10], Mini-batch [8/13], Loss: 0.7860\n",
      "INFO:__main__:Epoch [6/10], Mini-batch [9/13], Loss: 0.7163\n",
      "INFO:__main__:Epoch [6/10], Mini-batch [10/13], Loss: 0.5600\n",
      "INFO:__main__:Epoch [6/10], Mini-batch [11/13], Loss: 0.8146\n",
      "INFO:__main__:Epoch [6/10], Mini-batch [12/13], Loss: 0.5946\n",
      "INFO:__main__:Epoch [6/10], Mini-batch [13/13], Loss: 0.6302\n",
      "INFO:__main__:Epoch [6/10] completed, Average Loss: 0.6113\n",
      "INFO:__main__:Epoch [7/10], Mini-batch [1/13], Loss: 0.6540\n",
      "INFO:__main__:Epoch [7/10], Mini-batch [2/13], Loss: 0.6133\n",
      "INFO:__main__:Epoch [7/10], Mini-batch [3/13], Loss: 0.6805\n",
      "INFO:__main__:Epoch [7/10], Mini-batch [4/13], Loss: 0.6704\n",
      "INFO:__main__:Epoch [7/10], Mini-batch [5/13], Loss: 0.8388\n",
      "INFO:__main__:Epoch [7/10], Mini-batch [6/13], Loss: 0.8420\n",
      "INFO:__main__:Epoch [7/10], Mini-batch [7/13], Loss: 0.9726\n",
      "INFO:__main__:Epoch [7/10], Mini-batch [8/13], Loss: 0.8245\n",
      "INFO:__main__:Epoch [7/10], Mini-batch [9/13], Loss: 0.5749\n",
      "INFO:__main__:Epoch [7/10], Mini-batch [10/13], Loss: -1.0372\n",
      "INFO:__main__:Epoch [7/10], Mini-batch [11/13], Loss: 0.6766\n",
      "INFO:__main__:Epoch [7/10], Mini-batch [12/13], Loss: 1.0643\n",
      "INFO:__main__:Epoch [7/10], Mini-batch [13/13], Loss: 0.3835\n",
      "INFO:__main__:Epoch [7/10] completed, Average Loss: 0.5968\n",
      "INFO:__main__:Epoch [8/10], Mini-batch [1/13], Loss: 0.4371\n",
      "INFO:__main__:Epoch [8/10], Mini-batch [2/13], Loss: 0.7881\n",
      "INFO:__main__:Epoch [8/10], Mini-batch [3/13], Loss: 0.7369\n",
      "INFO:__main__:Epoch [8/10], Mini-batch [4/13], Loss: 0.9642\n",
      "INFO:__main__:Epoch [8/10], Mini-batch [5/13], Loss: 0.6523\n",
      "INFO:__main__:Epoch [8/10], Mini-batch [6/13], Loss: 0.8921\n",
      "INFO:__main__:Epoch [8/10], Mini-batch [7/13], Loss: 0.6180\n",
      "INFO:__main__:Epoch [8/10], Mini-batch [8/13], Loss: 0.7754\n",
      "INFO:__main__:Epoch [8/10], Mini-batch [9/13], Loss: 0.8520\n",
      "INFO:__main__:Epoch [8/10], Mini-batch [10/13], Loss: 0.6618\n",
      "INFO:__main__:Epoch [8/10], Mini-batch [11/13], Loss: -0.7766\n",
      "INFO:__main__:Epoch [8/10], Mini-batch [12/13], Loss: 0.6954\n",
      "INFO:__main__:Epoch [8/10], Mini-batch [13/13], Loss: 0.7778\n",
      "INFO:__main__:Epoch [8/10] completed, Average Loss: 0.6211\n",
      "INFO:__main__:Epoch [9/10], Mini-batch [1/13], Loss: 0.5039\n",
      "INFO:__main__:Epoch [9/10], Mini-batch [2/13], Loss: 0.7407\n",
      "INFO:__main__:Epoch [9/10], Mini-batch [3/13], Loss: 0.7781\n",
      "INFO:__main__:Epoch [9/10], Mini-batch [4/13], Loss: 0.5808\n",
      "INFO:__main__:Epoch [9/10], Mini-batch [5/13], Loss: 0.7599\n",
      "INFO:__main__:Epoch [9/10], Mini-batch [6/13], Loss: 0.7273\n",
      "INFO:__main__:Epoch [9/10], Mini-batch [7/13], Loss: 0.7488\n",
      "INFO:__main__:Epoch [9/10], Mini-batch [8/13], Loss: 0.7581\n",
      "INFO:__main__:Epoch [9/10], Mini-batch [9/13], Loss: 0.7852\n",
      "INFO:__main__:Epoch [9/10], Mini-batch [10/13], Loss: 1.0772\n",
      "INFO:__main__:Epoch [9/10], Mini-batch [11/13], Loss: 0.6585\n",
      "INFO:__main__:Epoch [9/10], Mini-batch [12/13], Loss: -0.3560\n",
      "INFO:__main__:Epoch [9/10], Mini-batch [13/13], Loss: 0.8169\n",
      "INFO:__main__:Epoch [9/10] completed, Average Loss: 0.6600\n",
      "INFO:__main__:Epoch [10/10], Mini-batch [1/13], Loss: 1.1720\n",
      "INFO:__main__:Epoch [10/10], Mini-batch [2/13], Loss: 0.7228\n",
      "INFO:__main__:Epoch [10/10], Mini-batch [3/13], Loss: 0.6183\n",
      "INFO:__main__:Epoch [10/10], Mini-batch [4/13], Loss: 0.7418\n",
      "INFO:__main__:Epoch [10/10], Mini-batch [5/13], Loss: 0.7759\n",
      "INFO:__main__:Epoch [10/10], Mini-batch [6/13], Loss: 0.6324\n",
      "INFO:__main__:Epoch [10/10], Mini-batch [7/13], Loss: 0.7578\n",
      "INFO:__main__:Epoch [10/10], Mini-batch [8/13], Loss: 0.6838\n",
      "INFO:__main__:Epoch [10/10], Mini-batch [9/13], Loss: 0.7867\n",
      "INFO:__main__:Epoch [10/10], Mini-batch [10/13], Loss: 0.9202\n",
      "INFO:__main__:Epoch [10/10], Mini-batch [11/13], Loss: 0.7424\n",
      "INFO:__main__:Epoch [10/10], Mini-batch [12/13], Loss: -0.0319\n",
      "INFO:__main__:Epoch [10/10], Mini-batch [13/13], Loss: 0.7611\n",
      "INFO:__main__:Epoch [10/10] completed, Average Loss: 0.7141\n",
      "INFO:__main__:Model saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Neighborhood Features\n",
    "neighborhood_ids = torch.arange(num_neighborhoods)\n",
    "logger.info(f\"neighborhood_ids shape {neighborhood_ids.shape}\")\n",
    "\n",
    "# Time Features\n",
    "time_features = torch.zeros(spatial_dimension, 1, time_feature_dim)\n",
    "for nid in range(num_neighborhoods):\n",
    "    # Filter rows for the current neighborhood\n",
    "    neighborhood_data = weekly_events_df[weekly_events_df[\"Neighbourhood Number\"] == neighbourhood_mappings[nid]]\n",
    "\n",
    "    if not neighborhood_data.empty:\n",
    "        # Use \"year\" and \"week_of_year\" as features\n",
    "        year_mean = neighborhood_data[\"year\"].mean()\n",
    "        week_mean = neighborhood_data[\"week_of_year\"].mean()\n",
    "\n",
    "        # Combine them into time features (e.g., [mean year, mean week])\n",
    "        time_features[nid, 0, :] = torch.tensor([year_mean, week_mean])\n",
    "    else:\n",
    "        # Default to zero if no data for the neighborhood\n",
    "        time_features[nid, 0, :] = torch.zeros(time_feature_dim)\n",
    "\n",
    "logger.info(f\"time_features shape: {time_features.shape}\")\n",
    "\n",
    "# Building Features\n",
    "building_type_ids = torch.arange(num_building_types).repeat(spatial_dimension, 1)\n",
    "logger.info(f\"building_type_ids shape {building_type_ids.shape}\")\n",
    "\n",
    "# Building Counts\n",
    "building_counts_np = neighbourhood_feature_df[build_type_list].fillna(0).to_numpy(dtype=np.int32)\n",
    "building_counts = torch.from_numpy(building_counts_np).unsqueeze(1)  # Temporal dimension = 1\n",
    "logger.info(f\"building_counts shape {building_counts.shape}\")\n",
    "\n",
    "# Demographic Features\n",
    "population = torch.from_numpy(population_np).float()\n",
    "logger.info(f\"population shape {population.shape}\")\n",
    "\n",
    "# Event Features\n",
    "event_type_ids = torch.randint(0, num_event_types, (spatial_dimension, 1))  # Temporal dimension = 1\n",
    "logger.info(f\"event_type_ids shape {event_type_ids.shape}\")\n",
    "\n",
    "equipment_ids = torch.randint(0, num_equipment_types, (spatial_dimension, 1))  # Temporal dimension = 1\n",
    "logger.info(f\"equipment_ids shape {equipment_ids.shape}\")\n",
    "\n",
    "# Target Values\n",
    "agg_data = weekly_events_df.groupby(['year', 'week_of_year', 'Neighbourhood Number']).agg({\n",
    "    'Rc_description': ' '.join,  # Concatenate descriptions (or other aggregation if needed)\n",
    "    'event_count': 'sum'         # Sum event counts\n",
    "}).reset_index()\n",
    "\n",
    "unique_week_year_combinations = agg_data[['year', 'week_of_year']].drop_duplicates()\n",
    "targets = torch.zeros((num_neighborhoods,), dtype=torch.float32)\n",
    "\n",
    "for i, neighbourhood in enumerate(neighbourhood_feature_df['Neighbourhood_Number']):\n",
    "    neighbourhood_data = agg_data[agg_data['Neighbourhood Number'] == neighbourhood]\n",
    "    # Sum of event counts for each (year, week_of_year) combination\n",
    "    for k, (year, week) in enumerate(unique_week_year_combinations.itertuples(index=False)):\n",
    "        event_count = neighbourhood_data[(neighbourhood_data['year'] == year) &\n",
    "                                         (neighbourhood_data['week_of_year'] == week)]['event_count'].sum()\n",
    "        targets[i] = event_count  # Aggregated for the entire week\n",
    "logger.info(f\"targets shape {targets.shape}\")\n",
    "\n",
    "# Instantiate the DataLoader and EmergencyEventPredictor\n",
    "dataset = NeighborhoodDataset(neighborhood_ids, time_features, building_type_ids, building_counts,\n",
    "                              population, event_type_ids, equipment_ids, targets)\n",
    "dataloader = DataLoader(dataset, batch_size=mini_batch_size, shuffle=True)\n",
    "\n",
    "model = EmergencyEventPredictor(\n",
    "    embedding_module=embedding_module,\n",
    "    embed_dim=64,\n",
    "    num_heads=4,\n",
    "    num_layers=2\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.PoissonNLLLoss()\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for i, (_neighborhood_ids, _time_features, _building_type_ids, _building_counts,\n",
    "            _population, _event_type_ids, _equipment_ids, _targets) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        _predictions = model(_neighborhood_ids, _time_features, _building_type_ids,\n",
    "                             _building_counts, _population, _event_type_ids, _equipment_ids)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(_predictions, _targets)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        mini_batch_loss = loss.item()\n",
    "        epoch_loss += mini_batch_loss\n",
    "        logger.info(f\"Epoch [{epoch+1}/{num_epochs}], Mini-batch [{i + 1}/{len(dataloader)}], Loss: {mini_batch_loss:.4f}\")\n",
    "\n",
    "    logger.info(f\"Epoch [{epoch+1}/{num_epochs}] completed, Average Loss: {(epoch_loss / len(dataloader)):.4f}\")\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), \"transformer_model_weekly.pth\")\n",
    "logger.info(\"Model saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qRhp67EP-s8N"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neighborhood_ids 1 size torch.Size([377])\n",
      "INFO:__main__:Epoch [1/10], Mini-batch [1/13], Loss: 0.9529\n",
      "INFO:__main__:Epoch [1/10], Mini-batch [2/13], Loss: 0.8118\n",
      "INFO:__main__:Epoch [1/10], Mini-batch [3/13], Loss: 0.8702\n",
      "INFO:__main__:Epoch [1/10], Mini-batch [4/13], Loss: 0.7552\n",
      "INFO:__main__:Epoch [1/10], Mini-batch [5/13], Loss: 0.9175\n",
      "INFO:__main__:Epoch [1/10], Mini-batch [6/13], Loss: 1.7678\n",
      "INFO:__main__:Epoch [1/10], Mini-batch [7/13], Loss: 0.8040\n",
      "INFO:__main__:Epoch [1/10], Mini-batch [8/13], Loss: 0.6451\n",
      "INFO:__main__:Epoch [1/10], Mini-batch [9/13], Loss: 0.7076\n",
      "INFO:__main__:Epoch [1/10], Mini-batch [10/13], Loss: 0.6906\n",
      "INFO:__main__:Epoch [1/10], Mini-batch [11/13], Loss: 1.0096\n",
      "INFO:__main__:Epoch [1/10], Mini-batch [12/13], Loss: 0.5660\n",
      "INFO:__main__:Epoch [1/10], Mini-batch [13/13], Loss: 1.0300\n",
      "INFO:__main__:Epoch [1/10] completed, Average Loss: 0.8868\n",
      "neighborhood_ids 1 size torch.Size([377])\n",
      "INFO:__main__:Epoch [2/10], Mini-batch [1/13], Loss: 0.6182\n",
      "INFO:__main__:Epoch [2/10], Mini-batch [2/13], Loss: 0.9901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hardy\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Epoch [2/10], Mini-batch [3/13], Loss: 0.8366\n",
      "INFO:__main__:Epoch [2/10], Mini-batch [4/13], Loss: 0.5476\n",
      "INFO:__main__:Epoch [2/10], Mini-batch [5/13], Loss: 0.9362\n",
      "INFO:__main__:Epoch [2/10], Mini-batch [6/13], Loss: 0.7679\n",
      "INFO:__main__:Epoch [2/10], Mini-batch [7/13], Loss: 0.7617\n",
      "INFO:__main__:Epoch [2/10], Mini-batch [8/13], Loss: 0.7736\n",
      "INFO:__main__:Epoch [2/10], Mini-batch [9/13], Loss: -0.4613\n",
      "INFO:__main__:Epoch [2/10], Mini-batch [10/13], Loss: 1.0536\n",
      "INFO:__main__:Epoch [2/10], Mini-batch [11/13], Loss: 0.9445\n",
      "INFO:__main__:Epoch [2/10], Mini-batch [12/13], Loss: 1.0618\n",
      "INFO:__main__:Epoch [2/10], Mini-batch [13/13], Loss: 0.7591\n",
      "INFO:__main__:Epoch [2/10] completed, Average Loss: 0.7377\n",
      "neighborhood_ids 1 size torch.Size([377])\n",
      "INFO:__main__:Epoch [3/10], Mini-batch [1/13], Loss: 0.7865\n",
      "INFO:__main__:Epoch [3/10], Mini-batch [2/13], Loss: 0.8658\n",
      "INFO:__main__:Epoch [3/10], Mini-batch [3/13], Loss: 0.7609\n",
      "INFO:__main__:Epoch [3/10], Mini-batch [4/13], Loss: 0.8013\n",
      "INFO:__main__:Epoch [3/10], Mini-batch [5/13], Loss: 0.7196\n",
      "INFO:__main__:Epoch [3/10], Mini-batch [6/13], Loss: 0.6603\n",
      "INFO:__main__:Epoch [3/10], Mini-batch [7/13], Loss: 0.8438\n",
      "INFO:__main__:Epoch [3/10], Mini-batch [8/13], Loss: -0.3917\n",
      "INFO:__main__:Epoch [3/10], Mini-batch [9/13], Loss: 0.6947\n",
      "INFO:__main__:Epoch [3/10], Mini-batch [10/13], Loss: 0.8098\n",
      "INFO:__main__:Epoch [3/10], Mini-batch [11/13], Loss: 0.6706\n",
      "INFO:__main__:Epoch [3/10], Mini-batch [12/13], Loss: 1.0323\n",
      "INFO:__main__:Epoch [3/10], Mini-batch [13/13], Loss: 0.7285\n",
      "INFO:__main__:Epoch [3/10] completed, Average Loss: 0.6909\n",
      "neighborhood_ids 1 size torch.Size([377])\n",
      "INFO:__main__:Epoch [4/10], Mini-batch [1/13], Loss: 0.8141\n",
      "INFO:__main__:Epoch [4/10], Mini-batch [2/13], Loss: 0.7696\n",
      "INFO:__main__:Epoch [4/10], Mini-batch [3/13], Loss: 0.4864\n",
      "INFO:__main__:Epoch [4/10], Mini-batch [4/13], Loss: 1.1109\n",
      "INFO:__main__:Epoch [4/10], Mini-batch [5/13], Loss: 0.4548\n",
      "INFO:__main__:Epoch [4/10], Mini-batch [6/13], Loss: -0.9321\n",
      "INFO:__main__:Epoch [4/10], Mini-batch [7/13], Loss: 0.6073\n",
      "INFO:__main__:Epoch [4/10], Mini-batch [8/13], Loss: 0.6694\n",
      "INFO:__main__:Epoch [4/10], Mini-batch [9/13], Loss: 0.8391\n",
      "INFO:__main__:Epoch [4/10], Mini-batch [10/13], Loss: 0.7984\n",
      "INFO:__main__:Epoch [4/10], Mini-batch [11/13], Loss: 0.6464\n",
      "INFO:__main__:Epoch [4/10], Mini-batch [12/13], Loss: 0.9230\n",
      "INFO:__main__:Epoch [4/10], Mini-batch [13/13], Loss: 1.0156\n",
      "INFO:__main__:Epoch [4/10] completed, Average Loss: 0.6310\n",
      "neighborhood_ids 1 size torch.Size([377])\n",
      "INFO:__main__:Epoch [5/10], Mini-batch [1/13], Loss: 0.9002\n",
      "INFO:__main__:Epoch [5/10], Mini-batch [2/13], Loss: 0.8489\n",
      "INFO:__main__:Epoch [5/10], Mini-batch [3/13], Loss: 0.9639\n",
      "INFO:__main__:Epoch [5/10], Mini-batch [4/13], Loss: 0.9862\n",
      "INFO:__main__:Epoch [5/10], Mini-batch [5/13], Loss: 0.7774\n",
      "INFO:__main__:Epoch [5/10], Mini-batch [6/13], Loss: 0.6663\n",
      "INFO:__main__:Epoch [5/10], Mini-batch [7/13], Loss: 0.6612\n",
      "INFO:__main__:Epoch [5/10], Mini-batch [8/13], Loss: -0.2855\n",
      "INFO:__main__:Epoch [5/10], Mini-batch [9/13], Loss: 0.8260\n",
      "INFO:__main__:Epoch [5/10], Mini-batch [10/13], Loss: 0.7358\n",
      "INFO:__main__:Epoch [5/10], Mini-batch [11/13], Loss: 0.7791\n",
      "INFO:__main__:Epoch [5/10], Mini-batch [12/13], Loss: 0.8797\n",
      "INFO:__main__:Epoch [5/10], Mini-batch [13/13], Loss: 0.3229\n",
      "INFO:__main__:Epoch [5/10] completed, Average Loss: 0.6971\n",
      "neighborhood_ids 1 size torch.Size([377])\n",
      "INFO:__main__:Epoch [6/10], Mini-batch [1/13], Loss: 0.6202\n",
      "INFO:__main__:Epoch [6/10], Mini-batch [2/13], Loss: -0.9127\n",
      "INFO:__main__:Epoch [6/10], Mini-batch [3/13], Loss: 0.8447\n",
      "INFO:__main__:Epoch [6/10], Mini-batch [4/13], Loss: 0.5216\n",
      "INFO:__main__:Epoch [6/10], Mini-batch [5/13], Loss: 0.6591\n",
      "INFO:__main__:Epoch [6/10], Mini-batch [6/13], Loss: 0.7408\n",
      "INFO:__main__:Epoch [6/10], Mini-batch [7/13], Loss: 1.0645\n",
      "INFO:__main__:Epoch [6/10], Mini-batch [8/13], Loss: 0.8673\n",
      "INFO:__main__:Epoch [6/10], Mini-batch [9/13], Loss: 0.9273\n",
      "INFO:__main__:Epoch [6/10], Mini-batch [10/13], Loss: 1.2975\n",
      "INFO:__main__:Epoch [6/10], Mini-batch [11/13], Loss: 0.4984\n",
      "INFO:__main__:Epoch [6/10], Mini-batch [12/13], Loss: 1.4144\n",
      "INFO:__main__:Epoch [6/10], Mini-batch [13/13], Loss: 0.8434\n",
      "INFO:__main__:Epoch [6/10] completed, Average Loss: 0.7220\n",
      "neighborhood_ids 1 size torch.Size([377])\n",
      "INFO:__main__:Epoch [7/10], Mini-batch [1/13], Loss: 0.7464\n",
      "INFO:__main__:Epoch [7/10], Mini-batch [2/13], Loss: 0.9887\n",
      "INFO:__main__:Epoch [7/10], Mini-batch [3/13], Loss: 1.0629\n",
      "INFO:__main__:Epoch [7/10], Mini-batch [4/13], Loss: 0.9348\n",
      "INFO:__main__:Epoch [7/10], Mini-batch [5/13], Loss: 0.9882\n",
      "INFO:__main__:Epoch [7/10], Mini-batch [6/13], Loss: 0.9810\n",
      "INFO:__main__:Epoch [7/10], Mini-batch [7/13], Loss: 0.6526\n",
      "INFO:__main__:Epoch [7/10], Mini-batch [8/13], Loss: 0.1738\n",
      "INFO:__main__:Epoch [7/10], Mini-batch [9/13], Loss: 0.8196\n",
      "INFO:__main__:Epoch [7/10], Mini-batch [10/13], Loss: 0.7552\n",
      "INFO:__main__:Epoch [7/10], Mini-batch [11/13], Loss: 0.8652\n",
      "INFO:__main__:Epoch [7/10], Mini-batch [12/13], Loss: 0.7954\n",
      "INFO:__main__:Epoch [7/10], Mini-batch [13/13], Loss: 0.7736\n",
      "INFO:__main__:Epoch [7/10] completed, Average Loss: 0.8106\n",
      "neighborhood_ids 1 size torch.Size([377])\n",
      "INFO:__main__:Epoch [8/10], Mini-batch [1/13], Loss: -0.5972\n",
      "INFO:__main__:Epoch [8/10], Mini-batch [2/13], Loss: 0.5957\n",
      "INFO:__main__:Epoch [8/10], Mini-batch [3/13], Loss: 0.7555\n",
      "INFO:__main__:Epoch [8/10], Mini-batch [4/13], Loss: 0.8006\n",
      "INFO:__main__:Epoch [8/10], Mini-batch [5/13], Loss: 0.8834\n",
      "INFO:__main__:Epoch [8/10], Mini-batch [6/13], Loss: 0.8876\n",
      "INFO:__main__:Epoch [8/10], Mini-batch [7/13], Loss: 0.5465\n",
      "INFO:__main__:Epoch [8/10], Mini-batch [8/13], Loss: 0.4135\n",
      "INFO:__main__:Epoch [8/10], Mini-batch [9/13], Loss: 0.7199\n",
      "INFO:__main__:Epoch [8/10], Mini-batch [10/13], Loss: 0.8933\n",
      "INFO:__main__:Epoch [8/10], Mini-batch [11/13], Loss: 1.1073\n",
      "INFO:__main__:Epoch [8/10], Mini-batch [12/13], Loss: 0.4997\n",
      "INFO:__main__:Epoch [8/10], Mini-batch [13/13], Loss: 0.6826\n",
      "INFO:__main__:Epoch [8/10] completed, Average Loss: 0.6299\n",
      "neighborhood_ids 1 size torch.Size([377])\n",
      "INFO:__main__:Epoch [9/10], Mini-batch [1/13], Loss: 0.6172\n",
      "INFO:__main__:Epoch [9/10], Mini-batch [2/13], Loss: 0.5710\n",
      "INFO:__main__:Epoch [9/10], Mini-batch [3/13], Loss: 0.7265\n",
      "INFO:__main__:Epoch [9/10], Mini-batch [4/13], Loss: 0.8540\n",
      "INFO:__main__:Epoch [9/10], Mini-batch [5/13], Loss: 0.7165\n",
      "INFO:__main__:Epoch [9/10], Mini-batch [6/13], Loss: -0.9496\n",
      "INFO:__main__:Epoch [9/10], Mini-batch [7/13], Loss: 0.8116\n",
      "INFO:__main__:Epoch [9/10], Mini-batch [8/13], Loss: 0.5507\n",
      "INFO:__main__:Epoch [9/10], Mini-batch [9/13], Loss: 0.6717\n",
      "INFO:__main__:Epoch [9/10], Mini-batch [10/13], Loss: 0.7750\n",
      "INFO:__main__:Epoch [9/10], Mini-batch [11/13], Loss: 0.7697\n",
      "INFO:__main__:Epoch [9/10], Mini-batch [12/13], Loss: 0.8695\n",
      "INFO:__main__:Epoch [9/10], Mini-batch [13/13], Loss: 0.7628\n",
      "INFO:__main__:Epoch [9/10] completed, Average Loss: 0.5959\n",
      "neighborhood_ids 1 size torch.Size([377])\n",
      "INFO:__main__:Epoch [10/10], Mini-batch [1/13], Loss: 0.8305\n",
      "INFO:__main__:Epoch [10/10], Mini-batch [2/13], Loss: 0.5617\n",
      "INFO:__main__:Epoch [10/10], Mini-batch [3/13], Loss: 0.8928\n",
      "INFO:__main__:Epoch [10/10], Mini-batch [4/13], Loss: 0.7658\n",
      "INFO:__main__:Epoch [10/10], Mini-batch [5/13], Loss: 0.8440\n",
      "INFO:__main__:Epoch [10/10], Mini-batch [6/13], Loss: 0.7276\n",
      "INFO:__main__:Epoch [10/10], Mini-batch [7/13], Loss: -0.9033\n",
      "INFO:__main__:Epoch [10/10], Mini-batch [8/13], Loss: 0.5708\n",
      "INFO:__main__:Epoch [10/10], Mini-batch [9/13], Loss: 0.4602\n",
      "INFO:__main__:Epoch [10/10], Mini-batch [10/13], Loss: 1.0197\n",
      "INFO:__main__:Epoch [10/10], Mini-batch [11/13], Loss: 0.5949\n",
      "INFO:__main__:Epoch [10/10], Mini-batch [12/13], Loss: 0.7860\n",
      "INFO:__main__:Epoch [10/10], Mini-batch [13/13], Loss: 0.7816\n",
      "INFO:__main__:Epoch [10/10] completed, Average Loss: 0.6102\n",
      "neighborhood_ids 2 size torch.Size([377])\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the DataLoader and EmergencyEventPredictor\n",
    "dataset = NeighborhoodDataset(neighborhood_ids, time_features, building_type_ids, building_counts,\n",
    "                              population, event_type_ids, equipment_ids, targets)\n",
    "dataloader = DataLoader(dataset, batch_size=mini_batch_size, shuffle=True)\n",
    "\n",
    "model = EmergencyEventPredictor(\n",
    "    embedding_module=embedding_module,\n",
    "    embed_dim=64,\n",
    "    num_heads=4,\n",
    "    num_layers=2\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.PoissonNLLLoss()\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "  model.train()\n",
    "  epoch_loss = 0\n",
    "\n",
    "  print(f\"neighborhood_ids 1 size {neighborhood_ids.shape}\")\n",
    "\n",
    "  for i, (_neighborhood_ids, _time_features, _building_type_ids, _building_counts,\n",
    "          _population, _event_type_ids, _equipment_ids, _targets) in enumerate(dataloader):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass\n",
    "    _predictions = model(_neighborhood_ids, _time_features, _building_type_ids,\n",
    "                        _building_counts, _population, _event_type_ids, _equipment_ids)\n",
    "\n",
    "    # Compute loss\n",
    "    loss = criterion(_predictions, _targets)\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    mini_batch_loss = loss.item()\n",
    "    epoch_loss += mini_batch_loss\n",
    "    logger.info(f\"Epoch [{epoch+1}/{num_epochs}], Mini-batch [{i + 1}/{len(dataloader)}], Loss: {mini_batch_loss:.4f}\")\n",
    "\n",
    "  logger.info(f\"Epoch [{epoch+1}/{num_epochs}] completed, Average Loss: {(epoch_loss / len(dataloader)):.4f}\")\n",
    "\n",
    "print(f\"neighborhood_ids 2 size {neighborhood_ids.shape}\")\n",
    "# # Save the trained model\n",
    "# torch.save(model.state_dict(), \"transformer_model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9TvUntsoge8Y"
   },
   "source": [
    "**Transformer Model Prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cxb72D9VpkkX",
    "outputId": "fe762711-2f22-4eb6-ef1d-e00e3503b670"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Predictions Shape: torch.Size([377])\n",
      "INFO:__main__:Predictions: tensor([-8.4596e-01, -4.1118e-01, -1.0190e+00,  6.7146e-01, -9.5901e-02,\n",
      "        -4.7638e-01,  1.0031e-01,  4.3799e-02,  6.2383e-01,  9.2592e-01,\n",
      "         7.4286e-01,  4.9988e-01,  6.1780e-01,  3.0728e-01,  7.3109e-01,\n",
      "         4.7078e-01,  7.5497e-01, -1.4704e-01,  5.6895e-01,  3.0706e-01,\n",
      "         2.7444e-01,  1.4233e-03, -2.1236e-01, -1.0866e+00,  3.3767e-02,\n",
      "        -5.1460e-02, -1.0146e+00, -2.4528e-01, -5.6907e-01, -1.0816e+00,\n",
      "         7.5412e-02, -1.0771e+00, -3.3736e-01, -4.6823e-01, -4.4859e-01,\n",
      "        -8.6387e-01, -1.8784e-01, -4.0200e-01, -1.7086e-01, -6.7623e-01,\n",
      "        -4.1963e-01, -4.6192e-04, -3.8136e-01,  2.1020e-01, -5.4405e-01,\n",
      "         3.2057e-01,  5.9276e-01, -3.2038e-01, -5.5142e-01, -2.3644e-01,\n",
      "        -4.2400e-01, -8.8856e-02, -4.3567e-01, -2.8675e-02,  7.4900e-01,\n",
      "        -5.0461e-02, -9.0832e-01, -3.6355e-01,  5.4279e-01,  3.1694e-01,\n",
      "        -2.9457e-01, -6.3361e-01, -5.3953e-01, -6.9335e-01, -4.8408e-01,\n",
      "        -1.6596e-01, -6.3863e-01, -1.5999e-01,  5.4539e-01, -1.4616e+00,\n",
      "         2.0057e-01, -2.8253e-01,  8.3675e-01, -7.6014e-01, -3.8091e-01,\n",
      "        -5.3945e-01, -5.2622e-01, -1.6989e-01, -2.0241e-01, -9.5160e-01,\n",
      "         1.4590e-01, -3.5980e-01,  5.9260e-01,  3.9402e-01,  6.5712e-01,\n",
      "        -5.6724e-01, -5.2984e-01, -1.5620e-01,  6.8171e-02, -8.3653e-01,\n",
      "         1.7576e-01, -4.3484e-01,  8.6832e-01,  6.2568e-01, -4.2595e-01,\n",
      "         2.2955e-02, -8.8566e-02,  1.6878e-02,  4.2993e-01, -3.9665e-03,\n",
      "        -4.6282e-01, -7.6436e-01, -3.9682e-01, -8.3507e-01,  3.0048e-01,\n",
      "        -1.7993e-01, -1.1058e-01,  1.9506e-02, -2.5349e-01,  9.6126e-01,\n",
      "        -9.6584e-02,  5.0152e-01,  6.3941e-01, -1.0263e+00, -8.5962e-01,\n",
      "         1.1286e-01, -1.9488e-01,  6.5837e-02, -2.2570e-01, -3.9299e-01,\n",
      "        -2.6134e-01, -3.6510e-01,  8.9403e-01,  2.5378e-01, -3.8117e-02,\n",
      "        -2.8784e-01,  2.9783e-01,  5.1485e-01, -5.9787e-01, -6.5650e-01,\n",
      "        -7.5492e-01,  8.2479e-01,  4.6038e-01, -2.8839e-01, -6.0178e-01,\n",
      "         8.6030e-02, -2.7971e-01, -6.5850e-02, -7.3723e-01, -9.4532e-02,\n",
      "         3.3667e-01, -5.0588e-01,  3.9130e-01, -5.7086e-02, -5.4876e-01,\n",
      "        -3.3540e-01,  3.2669e-01, -9.9456e-01,  4.2161e-01, -1.0772e+00,\n",
      "         3.9601e-01,  1.3345e-02, -1.5886e-01, -9.9338e-01, -3.4395e-02,\n",
      "         4.3491e-01, -1.6845e-01, -1.4058e-01,  6.7078e-01, -9.9509e-02,\n",
      "        -3.7143e-01, -1.1399e-01, -1.2254e-01, -4.6532e-01, -8.5233e-01,\n",
      "         1.3808e-02,  5.2574e-01,  2.9741e-01, -1.2319e-01, -4.3051e-01,\n",
      "        -4.8041e-01,  5.5719e-02,  2.4216e-01, -1.1633e+00, -4.2616e-01,\n",
      "        -7.0207e-02,  3.1750e-01, -3.4506e-01, -3.8747e-01, -8.5129e-01,\n",
      "         3.1039e-02, -2.8439e-01, -3.5539e-01, -2.6364e-01,  1.1224e-01,\n",
      "        -4.3616e-01, -7.5009e-01, -3.0710e-01, -4.2360e-01, -5.2111e-01,\n",
      "        -3.0080e-01, -2.0625e-01, -4.2268e-02, -1.1535e-01,  2.8945e-01,\n",
      "        -1.0426e-01, -5.3313e-01, -1.0065e-01,  3.1337e-01, -1.0125e+00,\n",
      "        -8.0030e-01, -7.2411e-01, -2.1642e-01, -1.1243e-01, -3.1621e-01,\n",
      "        -5.2773e-01,  9.3054e-02, -1.5057e-01, -3.1926e-01, -2.6342e-01,\n",
      "        -2.3592e-01, -6.1971e-01,  8.5975e-01, -4.8110e-01,  9.0173e-02,\n",
      "         1.8389e-01, -6.0629e-01,  5.5746e-01,  1.2584e-01, -5.6689e-01,\n",
      "        -9.6470e-01, -1.1446e+00, -8.1386e-01, -6.0913e-01,  9.0303e-01,\n",
      "         8.0627e-01, -6.8990e-01,  3.3838e-01, -2.1051e-01, -4.7543e-01,\n",
      "        -1.2264e-01,  4.7877e-01,  5.3574e-02, -2.5996e-01,  6.6225e-01,\n",
      "         7.2668e-01, -5.2958e-01, -3.5713e-02,  6.0481e-02,  6.0136e-01,\n",
      "        -3.8311e-02,  4.7117e-01, -7.5176e-01, -6.8097e-01, -2.7482e-01,\n",
      "        -3.6407e-01, -3.7866e-01, -9.1363e-01, -1.5783e-01,  5.6182e-01,\n",
      "        -3.6532e-01,  2.1039e-01, -4.3446e-01,  1.9114e-01, -4.7257e-01,\n",
      "        -2.4272e-01,  4.2904e-01, -1.0247e+00, -2.2786e-01, -1.6328e-01,\n",
      "         4.5703e-02, -4.5981e-01,  6.3890e-02,  5.0108e-01, -6.6622e-01,\n",
      "        -5.7354e-01, -4.5767e-02,  3.1153e-01, -2.2301e-02, -2.8941e-01,\n",
      "        -3.6791e-02, -8.1635e-01, -3.5128e-01,  3.7183e-02,  1.9690e-01,\n",
      "         1.0971e-01,  6.8177e-01,  4.9017e-02,  6.1801e-01,  6.3070e-01,\n",
      "         5.6458e-01,  7.0877e-01,  1.3656e-01,  5.5183e-01,  6.4881e-01,\n",
      "         7.3674e-01,  5.9360e-01,  6.4542e-01,  5.4901e-01, -1.3524e-01,\n",
      "         2.9800e-01,  6.4278e-01,  5.0802e-01,  4.3421e-01, -1.2502e-01,\n",
      "        -7.9011e-01,  3.6583e-01,  4.7990e-01, -2.9771e-01,  7.5018e-02,\n",
      "        -8.4307e-01, -1.6622e-01, -5.3917e-01, -4.2946e-01, -1.7939e-01,\n",
      "        -4.8119e-01, -8.9995e-01, -7.4778e-01, -8.7062e-01, -7.2390e-01,\n",
      "         4.6618e-01, -8.1548e-01, -3.4978e-01, -1.3358e-01, -8.4353e-01,\n",
      "        -5.8798e-01,  2.1082e-01, -7.0078e-01,  4.5073e-01, -3.9681e-01,\n",
      "         3.3594e-02, -8.3510e-01,  3.4654e-01,  1.0844e+00, -7.4611e-01,\n",
      "         6.5373e-01,  3.7531e-01, -3.7851e-01,  5.3101e-02,  7.1072e-02,\n",
      "        -3.5705e-01,  5.3611e-01, -1.0811e+00, -2.1646e-01, -5.7502e-01,\n",
      "        -3.9040e-01, -3.2281e-01, -2.4595e-01, -4.3601e-01, -3.3787e-01,\n",
      "        -3.9484e-01, -7.2400e-01, -3.3734e-01, -4.2114e-01,  5.2489e-01,\n",
      "         3.0496e-01,  3.0476e-01, -3.5937e-01, -5.5672e-01, -6.1983e-01,\n",
      "        -8.1043e-01,  5.2545e-01, -4.1890e-01, -6.2844e-01, -4.1764e-01,\n",
      "         5.9447e-01, -3.8292e-01, -8.3215e-01, -3.6262e-01,  1.6390e-01,\n",
      "        -5.5186e-02,  3.1672e-01,  3.2060e-01,  4.9620e-01,  6.2029e-01,\n",
      "        -6.2164e-01,  7.4860e-01, -3.6705e-01,  3.1034e-01, -4.1336e-01,\n",
      "         8.5881e-01,  2.1038e-01,  2.0255e-01,  4.9856e-01,  7.4126e-01,\n",
      "        -1.0208e+00,  6.4820e-01], grad_fn=<SqueezeBackward1>)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Define model parameters\n",
    "embed_dim = target_embed_dim  # Same as output dimension of CombinedEmbedding\n",
    "num_heads = 4\n",
    "num_layers = 2\n",
    "max_len = 7  # Sequence length (e.g., 7 days for a weekly prediction)\n",
    "\n",
    "# Instantiate the model\n",
    "model = EmergencyEventPredictor(\n",
    "    embedding_module=embedding_module,  # Replace with actual CombinedEmbedding instance\n",
    "    embed_dim=embed_dim,\n",
    "    num_heads=num_heads,\n",
    "    num_layers=num_layers,\n",
    "    max_len=max_len\n",
    ")\n",
    "\n",
    "# Forward pass to get predictions\n",
    "predictions = model(\n",
    "    neighborhood_ids=neighborhood_ids,\n",
    "    time_features=time_features,\n",
    "    building_type_ids=building_type_ids,\n",
    "    building_counts=building_counts,\n",
    "    population=population,\n",
    "    event_type_ids=event_type_ids,\n",
    "    equipment_ids=equipment_ids\n",
    ")\n",
    "\n",
    "logger.info(f\"Predictions Shape: {predictions.shape}\")\n",
    "logger.info(f\"Predictions: {predictions}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q9Kjcq-dgur_"
   },
   "source": [
    "**Output Visulization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "2D1qgftI2cL4",
    "outputId": "37e8dbeb-7e1a-4eca-dd94-c317f2c9d94b"
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Inconsistent shape between the condition and the input (got (377, 1) and (377,))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Define the plot\u001b[39;00m\n\u001b[0;32m      8\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m100\u001b[39m))\n\u001b[1;32m----> 9\u001b[0m sns\u001b[38;5;241m.\u001b[39mheatmap(predictions_np, annot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoolwarm\u001b[39m\u001b[38;5;124m\"\u001b[39m, cbar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, fmt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     10\u001b[0m             xticklabels\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDay 1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDay 2\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDay 3\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDay 4\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDay 5\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDay 6\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDay 7\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     11\u001b[0m             yticklabels\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNeighborhood \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(predictions_np\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])])\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Add titles and labels\u001b[39;00m\n\u001b[0;32m     14\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted Number of Events per Day for Each Neighborhood\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\hardy\\anaconda3\\Lib\\site-packages\\seaborn\\matrix.py:446\u001b[0m, in \u001b[0;36mheatmap\u001b[1;34m(data, vmin, vmax, cmap, center, robust, annot, fmt, annot_kws, linewidths, linecolor, cbar, cbar_kws, cbar_ax, square, xticklabels, yticklabels, mask, ax, **kwargs)\u001b[0m\n\u001b[0;32m    365\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Plot rectangular data as a color-encoded matrix.\u001b[39;00m\n\u001b[0;32m    366\u001b[0m \n\u001b[0;32m    367\u001b[0m \u001b[38;5;124;03mThis is an Axes-level function and will draw the heatmap into the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    443\u001b[0m \n\u001b[0;32m    444\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;66;03m# Initialize the plotter object\u001b[39;00m\n\u001b[1;32m--> 446\u001b[0m plotter \u001b[38;5;241m=\u001b[39m _HeatMapper(data, vmin, vmax, cmap, center, robust, annot, fmt,\n\u001b[0;32m    447\u001b[0m                       annot_kws, cbar, cbar_kws, xticklabels,\n\u001b[0;32m    448\u001b[0m                       yticklabels, mask)\n\u001b[0;32m    450\u001b[0m \u001b[38;5;66;03m# Add the pcolormesh kwargs here\u001b[39;00m\n\u001b[0;32m    451\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlinewidths\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m linewidths\n",
      "File \u001b[1;32mc:\\Users\\hardy\\anaconda3\\Lib\\site-packages\\seaborn\\matrix.py:115\u001b[0m, in \u001b[0;36m_HeatMapper.__init__\u001b[1;34m(self, data, vmin, vmax, cmap, center, robust, annot, fmt, annot_kws, cbar, cbar_kws, xticklabels, yticklabels, mask)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;66;03m# Validate the mask and convert to DataFrame\u001b[39;00m\n\u001b[0;32m    113\u001b[0m mask \u001b[38;5;241m=\u001b[39m _matrix_mask(data, mask)\n\u001b[1;32m--> 115\u001b[0m plot_data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mma\u001b[38;5;241m.\u001b[39mmasked_where(np\u001b[38;5;241m.\u001b[39masarray(mask), plot_data)\n\u001b[0;32m    117\u001b[0m \u001b[38;5;66;03m# Get good names for the rows and columns\u001b[39;00m\n\u001b[0;32m    118\u001b[0m xtickevery \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\hardy\\anaconda3\\Lib\\site-packages\\numpy\\ma\\core.py:1933\u001b[0m, in \u001b[0;36mmasked_where\u001b[1;34m(condition, a, copy)\u001b[0m\n\u001b[0;32m   1931\u001b[0m (cshape, ashape) \u001b[38;5;241m=\u001b[39m (cond\u001b[38;5;241m.\u001b[39mshape, a\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m   1932\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cshape \u001b[38;5;129;01mand\u001b[39;00m cshape \u001b[38;5;241m!=\u001b[39m ashape:\n\u001b[1;32m-> 1933\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInconsistent shape between the condition and the input\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1934\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m (got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (cshape, ashape))\n\u001b[0;32m   1935\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(a, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_mask\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m   1936\u001b[0m     cond \u001b[38;5;241m=\u001b[39m mask_or(cond, a\u001b[38;5;241m.\u001b[39m_mask)\n",
      "\u001b[1;31mIndexError\u001b[0m: Inconsistent shape between the condition and the input (got (377, 1) and (377,))"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Detach predictions and convert to NumPy for visualization\n",
    "predictions_np = predictions.detach().numpy()\n",
    "\n",
    "# Define the plot\n",
    "plt.figure(figsize=(12, 100))\n",
    "sns.heatmap(predictions_np, annot=True, cmap=\"coolwarm\", cbar=True, fmt=\".2f\",\n",
    "            xticklabels=[\"Day 1\", \"Day 2\", \"Day 3\", \"Day 4\", \"Day 5\", \"Day 6\", \"Day 7\"],\n",
    "            yticklabels=[f\"Neighborhood {i+1}\" for i in range(predictions_np.shape[0])])\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title(\"Predicted Number of Events per Day for Each Neighborhood\")\n",
    "plt.xlabel(\"Day of the Week\")\n",
    "plt.ylabel(\"Neighborhood\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting neighborhoods into train and validation sets\n",
    "train_indices, val_indices = train_test_split(\n",
    "    np.arange(num_neighborhoods), test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Prepare validation tensors\n",
    "val_neighborhood_ids = neighborhood_ids[val_indices]\n",
    "val_time_features = time_features[val_indices]\n",
    "val_building_type_ids = building_type_ids[val_indices]\n",
    "val_building_counts = building_counts[val_indices]\n",
    "val_population = population[val_indices]\n",
    "val_event_type_ids = event_type_ids[val_indices]\n",
    "val_equipment_ids = equipment_ids[val_indices]\n",
    "val_targets = targets[val_indices]\n",
    "\n",
    "# Create Validation Dataset and DataLoader\n",
    "val_dataset = NeighborhoodDataset(\n",
    "    neighborhood_ids=val_neighborhood_ids,\n",
    "    time_features=val_time_features,\n",
    "    building_type_ids=val_building_type_ids,\n",
    "    building_counts=val_building_counts,\n",
    "    population=val_population,\n",
    "    event_type_ids=val_event_type_ids,\n",
    "    equipment_ids=val_equipment_ids,\n",
    "    targets=val_targets\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# Validation Loop\n",
    "def validate_model(model, val_dataloader):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        i = 0\n",
    "        for (_neighborhood_ids, _time_features, _building_type_ids, _building_counts,\n",
    "             _population, _event_type_ids, _equipment_ids, _targets) in val_dataloader:\n",
    "            \n",
    "            # Forward pass\n",
    "            _predictions = model(_neighborhood_ids, _time_features, _building_type_ids,\n",
    "                                 _building_counts, _population, _event_type_ids, _equipment_ids)\n",
    "\n",
    "            # Collect predictions and true values\n",
    "            all_predictions.append(_predictions.cpu().numpy())\n",
    "            all_targets.append(_targets.cpu().numpy())\n",
    "    \n",
    "    # Combine all batches\n",
    "    all_predictions = np.concatenate(all_predictions, axis=0)\n",
    "    all_targets = np.concatenate(all_targets, axis=0)\n",
    "\n",
    "    # Compute metrics\n",
    "    print(f\"all_targets {all_targets.shape}, all_predictions {all_predictions.shape}\")\n",
    "    mae = mean_absolute_error(all_targets, all_predictions)\n",
    "    mse = mean_squared_error(all_targets, all_predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(all_targets, all_predictions)\n",
    "\n",
    "    print(f\"Validation Results:\")\n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "    print(f\"MSE: {mse:.4f}\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"R² Score: {r2:.4f}\")\n",
    "\n",
    "    return all_predictions, all_targets\n",
    "\n",
    "# Scatter Plot: Predicted vs. True Values\n",
    "def plot_predictions_vs_true(all_predictions, all_targets):\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.scatter(all_targets, all_predictions, alpha=0.5, edgecolor='k')\n",
    "    plt.plot([all_targets.min(), all_targets.max()], [all_targets.min(), all_targets.max()], 'r--')\n",
    "    plt.title(\"Predicted vs True Event Counts\")\n",
    "    plt.xlabel(\"True Event Counts\")\n",
    "    plt.ylabel(\"Predicted Event Counts\")\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "# Heatmap: Neighborhood Predictions Over Time\n",
    "def plot_heatmap(all_predictions, neighborhood_ids, days=[\"Day 1\", \"Day 2\", \"Day 3\", \"Day 4\", \"Day 5\", \"Day 6\", \"Day 7\"]):\n",
    "    plt.figure(figsize=(12, 20))\n",
    "    sns.heatmap(all_predictions, annot=True, cmap=\"coolwarm\", cbar=True, fmt=\".2f\",\n",
    "                xticklabels=days,\n",
    "                yticklabels=[f\"Neighborhood {i}\" for i in neighborhood_ids])\n",
    "    plt.title(\"Predicted Event Counts per Neighborhood per Day\")\n",
    "    plt.xlabel(\"Days\")\n",
    "    plt.ylabel(\"Neighborhood\")\n",
    "    plt.show()\n",
    "\n",
    "# Perform validation\n",
    "all_predictions, all_targets = validate_model(model, val_dataloader)\n",
    "\n",
    "# Visualize results\n",
    "plot_predictions_vs_true(all_predictions, all_targets)\n",
    "plot_heatmap(all_predictions, val_neighborhood_ids)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0956e1a7d24746f3a072e75d256dd023": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3655ab555c854f0fac30dc887d05a0b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5225edfaad754b54bbe5363ad2cfc4d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "635834afa9b042019823c5081ec8cefa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0956e1a7d24746f3a072e75d256dd023",
      "placeholder": "​",
      "style": "IPY_MODEL_3655ab555c854f0fac30dc887d05a0b6",
      "value": "Computing transition probabilities: 100%"
     }
    },
    "7bdcf4bb5a6e491eb5f29470d14aff6b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8da88441f8c84d5a9a7d8f6ca4526ceb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a173c1ee575742aebe887c7150149fb9",
      "placeholder": "​",
      "style": "IPY_MODEL_d50aee24efa4495ea741fe0d7e132c28",
      "value": " 403/403 [00:00&lt;00:00, 2427.50it/s]"
     }
    },
    "950ff52c23cb4c9a913ee758fc930452": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a173c1ee575742aebe887c7150149fb9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d50aee24efa4495ea741fe0d7e132c28": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ee5563d32cad45e9a94d2316bd206197": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7bdcf4bb5a6e491eb5f29470d14aff6b",
      "max": 403,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5225edfaad754b54bbe5363ad2cfc4d5",
      "value": 403
     }
    },
    "fd9ec72686d240f5b84b9fbbedbfcd73": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_635834afa9b042019823c5081ec8cefa",
       "IPY_MODEL_ee5563d32cad45e9a94d2316bd206197",
       "IPY_MODEL_8da88441f8c84d5a9a7d8f6ca4526ceb"
      ],
      "layout": "IPY_MODEL_950ff52c23cb4c9a913ee758fc930452"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
