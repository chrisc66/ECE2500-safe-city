{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "koEMtYfCoeZt",
    "outputId": "e9f651f0-15ea-41d4-e871-a5c899311260"
   },
   "outputs": [],
   "source": [
    "!pip install networkx node2vec\n",
    "!pip install numpy pandas scipy\n",
    "!pip install shapely geopandas contextily\n",
    "!pip install torch seaborn matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PObN0B-3Sk1w"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import networkx as nx\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from node2vec import Node2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Dataset Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  from google.colab import drive\n",
    "  logger.info(\"Running on Google Colab, reading dataset from drive\")\n",
    "  drive.mount(\"/content/drive\")\n",
    "  DATASET_PATH = \"/content/drive/MyDrive/ECE2500/EdmontonFireRescueServicesData\"\n",
    "except:\n",
    "  logger.info(\"Running locally, reading dataset from local file system\")\n",
    "  DATASET_PATH = \"./dataset/EdmontonFireRescueServicesData\"\n",
    "  if not os.path.exists(DATASET_PATH):\n",
    "    logger.critical(f\"Cannot find dataset directory, place dataset in {DATASET_PATH}\")\n",
    "    exit(1)\n",
    "\n",
    "UNIT_TRIP_PATH = os.path.join(DATASET_PATH, \"EFRS_Unit_Trip_Summary.csv\")\n",
    "EVENT_TRIP_PATH = os.path.join(DATASET_PATH, \"EFRS_Event_Trip_Summary.csv\")\n",
    "UNIT_HISTORY_2023_PATH = os.path.join(DATASET_PATH, \"UN_HI_2023.csv\")\n",
    "NEIGHBOURHOOD_PATH = os.path.join(DATASET_PATH, \"City_of_Edmonton_-_Neighbourhoods_20241022.csv\")\n",
    "FIRE_STATION_PATH = os.path.join(DATASET_PATH, \"Fire_Stations_20241027.csv\")\n",
    "NEIGHBOURHOOD_FEATURES_PATH = os.path.join(DATASET_PATH, \"neighbourhood_static_data_with_five_years_events.csv\")\n",
    "\n",
    "logger.debug(f\"Unit Trip: {UNIT_TRIP_PATH}\")\n",
    "logger.debug(f\"Event Trip: {EVENT_TRIP_PATH}\")\n",
    "logger.debug(f\"Unit History 2023: {UNIT_HISTORY_2023_PATH}\")\n",
    "logger.debug(f\"Neighbourhood: {NEIGHBOURHOOD_PATH}\")\n",
    "logger.debug(f\"Fire Stations: {FIRE_STATION_PATH}\")\n",
    "logger.debug(f\"Neighbourhood Features: {NEIGHBOURHOOD_FEATURES_PATH}\")\n",
    "\n",
    "unit_trip_df = pd.read_csv(UNIT_TRIP_PATH)\n",
    "event_trip_df = pd.read_csv(EVENT_TRIP_PATH)\n",
    "unit_history_2023_df = pd.read_csv(UNIT_HISTORY_2023_PATH)\n",
    "neighbourhood_df = pd.read_csv(NEIGHBOURHOOD_PATH)\n",
    "station_df = pd.read_csv(FIRE_STATION_PATH)\n",
    "neighbourhood_feature_df = pd.read_csv(NEIGHBOURHOOD_FEATURES_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fpSHJ3I6onMQ"
   },
   "source": [
    "**Data and Embedding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vkOrdiUYoiTw"
   },
   "outputs": [],
   "source": [
    "def generate_node2vec_embeddings(neighbourhood_df, num_neighborhoods, node2vec_dim=32):\n",
    "  \"\"\"\n",
    "  Generates Node2Vec embeddings for neighborhoods based on a sample adjacency graph.\n",
    "  num_neighborhoods: Number of neighborhoods (nodes in the graph).\n",
    "  node2vec_dim: Dimension of the embeddings to be generated.\n",
    "  \"\"\"\n",
    "\n",
    "  G = nx.Graph()\n",
    "\n",
    "  # Convert \"Geometry Multipolygon\" column to GeoSeries\n",
    "  neighbourhood_df['geometry'] = gpd.GeoSeries.from_wkt(neighbourhood_df['Geometry Multipolygon'])\n",
    "  neighbourhood_df['nid'] = range(num_neighborhoods)\n",
    "\n",
    "  # Assuming you have a way to define neighborhood connections based on proximity\n",
    "  # You can use the geometry information for this.\n",
    "  # Here's a placeholder for how you might connect neighborhoods based on proximity:\n",
    "\n",
    "  for i in range(num_neighborhoods):\n",
    "    for j in range(i + 1, num_neighborhoods):\n",
    "      # Use the new 'geometry' column for spatial operations\n",
    "      if neighbourhood_df['geometry'].iloc[i].intersects(neighbourhood_df['geometry'].iloc[j]):\n",
    "        G.add_edge(i, j)\n",
    "\n",
    "  # Alternatively, you could build a graph based on other criteria like sharing a boundary\n",
    "  node2vec = Node2Vec(G, dimensions=node2vec_dim, walk_length=10, num_walks=100, p=1, q=1)\n",
    "  node2vec_model = node2vec.fit()\n",
    "  node2vec_embeddings_np = np.array([node2vec_model.wv[str(i)] for i in range(num_neighborhoods)])\n",
    "  node2vec_embeddings = torch.from_numpy(node2vec_embeddings_np)\n",
    "  node2vec_emb_layer = nn.Embedding.from_pretrained(node2vec_embeddings, freeze=True)\n",
    "\n",
    "  return node2vec_emb_layer\n",
    "\n",
    "\n",
    "class Time2Vec(nn.Module):\n",
    "  \"\"\"\n",
    "  Time2Vec embedding module for temporal features\n",
    "\n",
    "  This captures both linear and periodic components for time-based features.\n",
    "  \"\"\"\n",
    "  def __init__(self, input_dim, embed_dim, act_function=torch.sin):\n",
    "    super(Time2Vec, self).__init__()\n",
    "    self.embed_dim = embed_dim // input_dim  # Embedding dimension per time feature\n",
    "    self.act_function = act_function       # Activation function for periodicity\n",
    "    self.weight = nn.Parameter(torch.randn(input_dim, self.embed_dim))\n",
    "    self.bias = nn.Parameter(torch.randn(input_dim, self.embed_dim))\n",
    "\n",
    "  def forward(self, x):\n",
    "    # Diagonal embedding for each time feature (day of week, hour, etc.)\n",
    "    x = torch.diag_embed(x)\n",
    "    x_affine = torch.matmul(x, self.weight) + self.bias\n",
    "    x_affine_0, x_affine_remain = torch.split(x_affine, [1, self.embed_dim - 1], dim=-1)\n",
    "    x_affine_remain = self.act_function(x_affine_remain)\n",
    "    return torch.cat([x_affine_0, x_affine_remain], dim=-1).view(x.size(0), x.size(1), -1)\n",
    "\n",
    "\n",
    "class NeighborhoodDataset(Dataset):\n",
    "    def __init__(self, neighborhood_ids, time_features, building_type_ids, building_counts,\n",
    "                 population, event_type_ids, equipment_ids, targets):\n",
    "        self.neighborhood_ids = neighborhood_ids  # Tensor of input neighborhood_ids\n",
    "        self.time_features = time_features  # Tensor of input time_features\n",
    "        self.building_type_ids = building_type_ids  # Tensor of input building_type_ids\n",
    "        self.building_counts = building_counts  # Tensor of input building_counts\n",
    "        self.population = population  # Tensor of input population\n",
    "        self.event_type_ids = event_type_ids  # Tensor of input event_type_ids\n",
    "        self.equipment_ids = equipment_ids  # Tensor of input equipment_ids\n",
    "        self.targets = targets    # Tensor of target values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.neighborhood_ids)  # Number of neighborhoods\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.neighborhood_ids[idx], self.time_features[idx], self.building_type_ids[idx], self.building_counts[idx],\n",
    "                self.population[idx], self.event_type_ids[idx], self.equipment_ids[idx], self.targets[idx])\n",
    "\n",
    "\n",
    "class CombinedEmbedding(nn.Module):\n",
    "  \"\"\"\n",
    "  Combined Embedding Module\n",
    "\n",
    "  Combines embeddings from Node2Vec, Time2Vec, building type/counts, population, event type, and equipment.\n",
    "  Projects the combined embedding to a target dimension (e.g., 64) for compatibility with transformer layers.\n",
    "  \"\"\"\n",
    "  def __init__(self, node2vec_emb_layer, time2vec_embed_dim, time_feature_dim,\n",
    "          num_building_types, building_type_embed_dim, population_embed_dim,\n",
    "          num_event_types, event_type_embed_dim, num_equipment_types, equipment_embed_dim,\n",
    "          target_embed_dim=64):  # Add target_embed_dim for projection\n",
    "    super(CombinedEmbedding, self).__init__()\n",
    "\n",
    "    # Embedding initialization code\n",
    "    self.node2vec_emb_layer = node2vec_emb_layer  # Precomputed Node2Vec embeddings\n",
    "    self.time2vec = Time2Vec(input_dim=time_feature_dim, embed_dim=time2vec_embed_dim)\n",
    "    self.building_type_embedding = nn.Embedding(num_building_types, building_type_embed_dim)\n",
    "    self.population_embedding = nn.Linear(1, population_embed_dim)\n",
    "    self.event_type_embedding = nn.Embedding(num_event_types, event_type_embed_dim)\n",
    "    self.equipment_embedding = nn.Embedding(num_equipment_types, equipment_embed_dim)\n",
    "\n",
    "    # Compute the combined embedding dimension before projection\n",
    "    self.projection_dim = (node2vec_emb_layer.embedding_dim + time2vec_embed_dim +\n",
    "                    building_type_embed_dim + population_embed_dim +\n",
    "                    event_type_embed_dim + equipment_embed_dim)\n",
    "\n",
    "    # Projection layer to reduce to target_embed_dim\n",
    "    self.projection_layer = nn.Linear(self.projection_dim, target_embed_dim)\n",
    "\n",
    "  def forward(self, neighborhood_ids, time_features, building_type_ids, building_counts,\n",
    "              population, event_type_ids, equipment_ids):\n",
    "    # Generate and combine embeddings\n",
    "    temporal_embeddings = self.time2vec(time_features)\n",
    "    logger.debug(f\"Temporal Embedding Shape: {temporal_embeddings.shape}\")\n",
    "    spatial_embeddings = self.node2vec_emb_layer(neighborhood_ids).unsqueeze(1).repeat(1, temporal_embeddings.size(1), 1) # [batch_size, temporal_dimensions, time2vec_embed_dim]\n",
    "    logger.debug(f\"Spatial Embedding Shape: {spatial_embeddings.shape}\")\n",
    "    building_embeddings = (self.building_type_embedding(building_type_ids) * building_counts.unsqueeze(-1)).sum(dim=2)\n",
    "    logger.debug(f\"Building Embedding Shape: {building_embeddings.shape}\")\n",
    "    population_embeddings = self.population_embedding(population.unsqueeze(-1)).unsqueeze(1).expand(-1, spatial_embeddings.size(1), -1)\n",
    "    logger.debug(f\"Population Embedding Shape: {population_embeddings.shape}\")\n",
    "    event_type_embeddings = self.event_type_embedding(event_type_ids)\n",
    "    logger.debug(f\"Event Type Embedding Shape: {event_type_embeddings.shape}\")\n",
    "    equipment_embeddings = self.equipment_embedding(equipment_ids)\n",
    "    logger.debug(f\"Equipment Embedding Shape: {equipment_embeddings.shape}\")\n",
    "\n",
    "    # Concatenate all embeddings into a single combined embedding\n",
    "    combined_embedding = torch.cat([spatial_embeddings, temporal_embeddings,\n",
    "                                    building_embeddings, population_embeddings,\n",
    "                                    event_type_embeddings, equipment_embeddings], dim=-1)\n",
    "\n",
    "    logger.debug(f\"Combined Embedding Shape before Projection: {combined_embedding.shape}\")\n",
    "\n",
    "    # Project to target dimension for compatibility (e.g., 64)\n",
    "    combined_embedding = self.projection_layer(combined_embedding)\n",
    "\n",
    "    return combined_embedding\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "  \"\"\"\n",
    "  Positional Encoding Module\n",
    "  \"\"\"\n",
    "  def __init__(self, embed_dim, max_len=7):  # 7 days in a week\n",
    "    super(PositionalEncoding, self).__init__()\n",
    "    position = torch.arange(0, max_len).unsqueeze(1)\n",
    "    div_term = torch.exp(torch.arange(0, embed_dim, 2) * -(math.log(10000.0) / embed_dim))\n",
    "    pe = torch.zeros(max_len, embed_dim)\n",
    "    pe[:, 0::2] = torch.sin(position * div_term)\n",
    "    pe[:, 1::2] = torch.cos(position * div_term)\n",
    "    self.pe = pe.unsqueeze(0)  # Shape: (1, max_len, embed_dim)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = x + self.pe[:, :x.size(1), :].to(x.device)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5mZCuFUYtYpm"
   },
   "source": [
    "**Transformer Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p3CHjlqytU2a"
   },
   "outputs": [],
   "source": [
    "# Transformer-based Emergency Event Predictor\n",
    "class EmergencyEventPredictor(nn.Module):\n",
    "  def __init__(self, embedding_module, embed_dim, num_heads, num_layers, max_len=7):\n",
    "    super(EmergencyEventPredictor, self).__init__()\n",
    "\n",
    "    # Embedding module (CombinedEmbedding) and positional encoding\n",
    "    self.embedding_module = embedding_module\n",
    "    self.positional_encoding = PositionalEncoding(embed_dim, max_len)\n",
    "\n",
    "    # Transformer Encoder\n",
    "    encoder_layer = nn.TransformerEncoderLayer(\n",
    "        d_model=embed_dim, nhead=num_heads, dim_feedforward=512, dropout=0.1\n",
    "    )\n",
    "    self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "    # Prediction head\n",
    "    self.fc_out = nn.Linear(embed_dim, 1)  # Output: predicting the number of events\n",
    "\n",
    "  def forward(self, neighborhood_ids, time_features, building_type_ids, building_counts,\n",
    "              population, event_type_ids, equipment_ids):\n",
    "\n",
    "    # Generate combined embeddings from the embedding module\n",
    "    x = self.embedding_module(neighborhood_ids, time_features, building_type_ids, building_counts,\n",
    "                              population, event_type_ids, equipment_ids)\n",
    "\n",
    "    # Apply positional encoding\n",
    "    x = self.positional_encoding(x)\n",
    "\n",
    "    # Pass through transformer encoder\n",
    "    x = self.transformer_encoder(x)\n",
    "\n",
    "    # Prediction layer (we apply it to each element in the sequence)\n",
    "    predictions = self.fc_out(x).squeeze(-1)  # Shape: [batch_size, sequence_length]\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Extraction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_type_list = [\n",
    "    'Apartment_Condo_1_to_4_stories', 'Apartment_Condo_5_or_more_stories',\n",
    "    'Duplex_Fourplex', 'Hotel_Motel',\n",
    "    'Institution_Collective_Residence', 'Manufactured_Mobile_Home',\n",
    "    'RV_Tent_Other', 'Row_House',\n",
    "    'Single_Detached_House'\n",
    "    ]\n",
    "event_type_list = event_trip_df['Rc_description'].unique()\n",
    "unit_type_list = unit_trip_df['unityp'].unique()\n",
    "\n",
    "num_neighborhoods = len(neighbourhood_df)\n",
    "num_building_types = len(build_type_list)\n",
    "num_event_types = len(event_type_list)\n",
    "num_equipment_types = len(unit_type_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neighbourhood Feature Cleaning\n",
    "\n",
    "neighbourhood_feature_full_df = pd.merge(neighbourhood_feature_df, neighbourhood_df, left_on='Neighbourhood_Number', right_on='Neighbourhood Number', how='outer')\n",
    "# Note: some neighbourhood is missing in neighbourhood_feature_df\n",
    "# len(neighbourhood_feature_df) # 377\n",
    "# len(neighbourhood_df) # 403\n",
    "# set(neighbourhood_df['Neighbourhood Number'].unique()) - set(neighbourhood_feature_df['Neighbourhood_Number'].unique())\n",
    "# len(neighbourhood_feature_full_df) # 403\n",
    "\n",
    "# Neighborhood IDs\n",
    "neighborhood_mapping = neighbourhood_feature_full_df['Neighbourhood Number'].unique() # mapping between index to neighborhood number\n",
    "\n",
    "# Building features\n",
    "# building_type_ids\n",
    "\n",
    "building_counts_np = neighbourhood_feature_full_df[build_type_list]\n",
    "building_counts_np.fillna(0, inplace=True)\n",
    "building_counts_np = building_counts_np.astype(int)\n",
    "building_counts_np = building_counts_np.to_numpy()\n",
    "\n",
    "# Demographic features\n",
    "neighbourhood_feature_full_df['Population'] = neighbourhood_feature_full_df['Area_Sq_Km'] * neighbourhood_feature_full_df['Population_per_Sq_km']\n",
    "population_np = neighbourhood_feature_full_df['Population']\n",
    "population_np.fillna(0, inplace=True)\n",
    "population_np = population_np.astype(int)\n",
    "population_np = population_np.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transformer Model Initalization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AEKcsqMG3l9T",
    "outputId": "71924b64-6378-4397-e650-8fc33a4f8b57"
   },
   "outputs": [],
   "source": [
    "# Embedding Parameter and Module\n",
    "\n",
    "node2vec_dim = 32\n",
    "time2vec_embed_dim = 63\n",
    "time_feature_dim = 3  # day of year, day of week, hour\n",
    "building_type_embed_dim = 16\n",
    "population_embed_dim = 8\n",
    "event_type_embed_dim = 16\n",
    "equipment_embed_dim = 16\n",
    "target_embed_dim = 64\n",
    "\n",
    "node2vec_emb_layer = generate_node2vec_embeddings(neighbourhood_df=neighbourhood_df, num_neighborhoods=num_neighborhoods, node2vec_dim=node2vec_dim)\n",
    "\n",
    "embedding_module = CombinedEmbedding(\n",
    "    node2vec_emb_layer=node2vec_emb_layer,\n",
    "    time2vec_embed_dim=time2vec_embed_dim,\n",
    "    time_feature_dim=time_feature_dim,\n",
    "    num_building_types=num_building_types,\n",
    "    building_type_embed_dim=building_type_embed_dim,\n",
    "    population_embed_dim=population_embed_dim,\n",
    "    num_event_types=num_event_types,\n",
    "    event_type_embed_dim=event_type_embed_dim,\n",
    "    num_equipment_types=num_equipment_types,\n",
    "    equipment_embed_dim=equipment_embed_dim,\n",
    "    target_embed_dim=target_embed_dim\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define batch and mini-batch\n",
    "\n",
    "mini_batch_size = 13\n",
    "batch_size = 31\n",
    "\n",
    "spatial_dimension = num_neighborhoods\n",
    "temporal_dimension = 7 # Predicting for a week\n",
    "\n",
    "# verify spatial_dimension = batch_size * mini_batch_size\n",
    "assert spatial_dimension == batch_size * mini_batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neighborhood Features\n",
    "neighborhood_ids = torch.arange(num_neighborhoods)\n",
    "logger.info(f\"neighborhood_ids shape {neighborhood_ids.shape}\")\n",
    "\n",
    "# Time Feature\n",
    "# TODO: use real data\n",
    "time_features = torch.zeros(spatial_dimension, temporal_dimension, time_feature_dim)\n",
    "time_features[:, :, 0] = torch.randint(1, 366, (spatial_dimension, temporal_dimension)) # Day of year (1–365)\n",
    "time_features[:, :, 1] = torch.randint(1, 8, (spatial_dimension, temporal_dimension)) # Day of week (1–7)\n",
    "time_features[:, :, 2] = torch.randint(0, 24, (spatial_dimension, temporal_dimension)) # Hour of the day (0–23)\n",
    "logger.info(f\"time_features shape {time_features.shape}\")\n",
    "\n",
    "# Building Features\n",
    "# TODO: use real data\n",
    "building_type_ids = torch.randint(0, num_building_types, (spatial_dimension, temporal_dimension, num_building_types))\n",
    "logger.info(f\"building_type_ids shape {building_type_ids.shape}\")\n",
    "\n",
    "# TODO: reduce building_counts size from [403, 7, 9] to [403, 9]\n",
    "# building_counts = torch.tensor(building_counts_np, dtype=torch.int32)\n",
    "building_counts = torch.from_numpy(building_counts_np).unsqueeze(1).repeat(1, temporal_dimension, 1)\n",
    "logger.info(f\"building_counts shape {building_counts.shape}\")\n",
    "\n",
    "# Demographic Features\n",
    "population = torch.from_numpy(population_np).float()\n",
    "logger.info(f\"population shape {population.shape}\")\n",
    "\n",
    "# Event Features\n",
    "# TODO: use real data\n",
    "event_type_ids = torch.randint(0, num_event_types, (spatial_dimension, temporal_dimension))\n",
    "logger.info(f\"event_type_ids shape {event_type_ids.shape}\")\n",
    "\n",
    "# TODO: use real data\n",
    "equipment_ids = torch.randint(0, num_equipment_types, (spatial_dimension, temporal_dimension))\n",
    "logger.info(f\"equipment_ids shape {equipment_ids.shape}\")\n",
    "\n",
    "# Target Values\n",
    "# TODO: use real data\n",
    "targets = torch.randint(0, 2, (spatial_dimension, temporal_dimension))\n",
    "logger.info(f\"targets shape {equipment_ids.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dutQ0WcSgki5"
   },
   "source": [
    "**Transformer Model Training Loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qRhp67EP-s8N"
   },
   "outputs": [],
   "source": [
    "# Instantiate the DataLoader and EmergencyEventPredictor\n",
    "dataset = NeighborhoodDataset(neighborhood_ids, time_features, building_type_ids, building_counts,\n",
    "                              population, event_type_ids, equipment_ids, targets)\n",
    "dataloader = DataLoader(dataset, batch_size=mini_batch_size, shuffle=True)\n",
    "\n",
    "model = EmergencyEventPredictor(\n",
    "    embedding_module=embedding_module,\n",
    "    embed_dim=64,\n",
    "    num_heads=4,\n",
    "    num_layers=2\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.PoissonNLLLoss()\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "  model.train()\n",
    "  epoch_loss = 0\n",
    "\n",
    "  for i, (neighborhood_ids, time_features, building_type_ids, building_counts,\n",
    "          population, event_type_ids, equipment_ids, targets) in enumerate(dataloader):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass\n",
    "    predictions = model(neighborhood_ids, time_features, building_type_ids,\n",
    "                        building_counts, population, event_type_ids, equipment_ids)\n",
    "\n",
    "    # Compute loss\n",
    "    loss = criterion(predictions, targets)\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    mini_batch_loss = loss.item()\n",
    "    epoch_loss += mini_batch_loss\n",
    "    logger.info(f\"Epoch [{epoch+1}/{num_epochs}], Mini-batch [{i + 1}/{len(dataloader)}], Loss: {mini_batch_loss:.4f}\")\n",
    "\n",
    "  logger.info(f\"Epoch [{epoch+1}/{num_epochs}] complete, Epoch Loss: {(epoch_loss / len(dataloader)):.4f}\")\n",
    "\n",
    "# # Save the trained model\n",
    "# torch.save(model.state_dict(), \"transformer_model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9TvUntsoge8Y"
   },
   "source": [
    "**Transformer Model Prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cxb72D9VpkkX",
    "outputId": "fe762711-2f22-4eb6-ef1d-e00e3503b670"
   },
   "outputs": [],
   "source": [
    "# Define model parameters\n",
    "embed_dim = target_embed_dim  # Same as output dimension of CombinedEmbedding\n",
    "num_heads = 4\n",
    "num_layers = 2\n",
    "max_len = 7  # Sequence length (e.g., 7 days for a weekly prediction)\n",
    "\n",
    "# Instantiate the model\n",
    "model = EmergencyEventPredictor(\n",
    "    embedding_module=embedding_module,  # Replace with actual CombinedEmbedding instance\n",
    "    embed_dim=embed_dim,\n",
    "    num_heads=num_heads,\n",
    "    num_layers=num_layers,\n",
    "    max_len=max_len\n",
    ")\n",
    "\n",
    "# Forward pass to get predictions\n",
    "predictions = model(\n",
    "    neighborhood_ids=neighborhood_ids,\n",
    "    time_features=time_features,\n",
    "    building_type_ids=building_type_ids,\n",
    "    building_counts=building_counts,\n",
    "    population=population,\n",
    "    event_type_ids=event_type_ids,\n",
    "    equipment_ids=equipment_ids\n",
    ")\n",
    "\n",
    "logger.info(f\"Predictions Shape: {predictions.shape}\")\n",
    "logger.info(f\"Predictions: {predictions}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q9Kjcq-dgur_"
   },
   "source": [
    "**Output Visulization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "2D1qgftI2cL4",
    "outputId": "37e8dbeb-7e1a-4eca-dd94-c317f2c9d94b"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Detach predictions and convert to NumPy for visualization\n",
    "predictions_np = predictions.detach().numpy()\n",
    "\n",
    "# Define the plot\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(predictions_np, annot=True, cmap=\"coolwarm\", cbar=True, fmt=\".2f\",\n",
    "            xticklabels=[\"Day 1\", \"Day 2\", \"Day 3\", \"Day 4\", \"Day 5\", \"Day 6\", \"Day 7\"],\n",
    "            yticklabels=[f\"Neighborhood {i+1}\" for i in range(predictions_np.shape[0])])\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title(\"Predicted Number of Events per Day for Each Neighborhood\")\n",
    "plt.xlabel(\"Day of the Week\")\n",
    "plt.ylabel(\"Neighborhood\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0956e1a7d24746f3a072e75d256dd023": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3655ab555c854f0fac30dc887d05a0b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5225edfaad754b54bbe5363ad2cfc4d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "635834afa9b042019823c5081ec8cefa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0956e1a7d24746f3a072e75d256dd023",
      "placeholder": "​",
      "style": "IPY_MODEL_3655ab555c854f0fac30dc887d05a0b6",
      "value": "Computing transition probabilities: 100%"
     }
    },
    "7bdcf4bb5a6e491eb5f29470d14aff6b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8da88441f8c84d5a9a7d8f6ca4526ceb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a173c1ee575742aebe887c7150149fb9",
      "placeholder": "​",
      "style": "IPY_MODEL_d50aee24efa4495ea741fe0d7e132c28",
      "value": " 403/403 [00:00&lt;00:00, 2427.50it/s]"
     }
    },
    "950ff52c23cb4c9a913ee758fc930452": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a173c1ee575742aebe887c7150149fb9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d50aee24efa4495ea741fe0d7e132c28": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ee5563d32cad45e9a94d2316bd206197": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7bdcf4bb5a6e491eb5f29470d14aff6b",
      "max": 403,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5225edfaad754b54bbe5363ad2cfc4d5",
      "value": 403
     }
    },
    "fd9ec72686d240f5b84b9fbbedbfcd73": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_635834afa9b042019823c5081ec8cefa",
       "IPY_MODEL_ee5563d32cad45e9a94d2316bd206197",
       "IPY_MODEL_8da88441f8c84d5a9a7d8f6ca4526ceb"
      ],
      "layout": "IPY_MODEL_950ff52c23cb4c9a913ee758fc930452"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
